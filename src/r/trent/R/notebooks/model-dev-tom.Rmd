---
title:  "Regression Model Development"
author: "Tom Shafer"
date:   "6/11/2020"
output: html_document
---

```{r setup, include=FALSE}
r_root <- rprojroot::find_rstudio_root_file()

knitr::opts_knit$set(root.dir = file.path(r_root))
knitr::opts_chunk$set(warning = FALSE, message = FALSE, dpi = 100)
knitr::opts_chunk$set(fig.width = 7, fig.height = 5)

ggplot2::theme_set(ggplot2::theme_minimal())
```

```{r init}
options(stringsAsFactors = F)

suppressPackageStartupMessages({
  library(tidyverse)
  library(here)
  library(rsample)
  library(glmmTMB)
  library(sjPlot)
  library(furrr)
  library(broom.mixed)
  library(yardstick)
  library(glue)
})

plan(multiprocess)
```


# Overview

## Objectives 

- [x] Generate data sample
- [x] Do not use pop weighting
- [x] Do feature engineering
- [x] Do basic feature selection
- [x] V-fold CV for evaluation
- [ ] Better standardization
- [ ] Collapse ages
- [ ] Select down mobility data
- [ ] Bigger CV sample
- [ ] Look at trajectories
- [ ] Add deltas

- [ ] Choose features
- [ ] Do residual analysis
- [ ] Add fittable covariate lag factor
- [ ] Add median age variable instead of age bins? Or in addition to?
- [x] add policy as a random slope (didn't work)
- [x] Do we want to exclude initial zeros?

## Results

---

# Helper functions and setup

```{r}
RANDOM_SEED <- -461698
```

```{r}
run_model_vfold <- function(formula, data, ziformula = ~0) {
  group_vfold_cv(sample_abt, group = county_fip, v = 5) %>% 
    future_pmap_dfr(~ {
      tr <- training(.x)
      te <- assessment(.x)
      id <- .y
      
      message("Running fold: ", id)
      
      model <- glmmTMB(
        formula, 
        data = tr,
        family = glmmTMB::nbinom2(), 
        ziformula = ziformula)
      
      pred_tr <- predict(model, tr, type = "conditional")
      pred_te <- predict(model, te, type = "conditional", allow.new.levels	= T)
      
      metrics_tr <- tribble(
        ~ metric, ~ value,
        "ccc",    ccc_vec(tr$target, pred_tr), 
        "huber",  huber_loss_vec(tr$target, pred_tr), 
        "mae",    mae_vec(tr$target, pred_tr), 
        "rsq",    rsq_vec(tr$target, pred_tr)
      )
      
      metrics_te <- tribble(
        ~ metric, ~ value,
        "ccc",    ccc_vec(te$target, pred_te), 
        "huber",  huber_loss_vec(tr$target, pred_tr), 
        "mae",    mae_vec(te$target, pred_te), 
        "rsq",    rsq_vec(te$target, pred_te)
      )
  
      tibble(
        id = id,
        object = list(model),
        tidy = list(suppressMessages(broom.mixed:::tidy.glmmTMB(model))),
        glance = list(suppressMessages(broom.mixed:::glance.glmmTMB(model))),
        train = list(metrics_tr),
        test = list(metrics_te)
      )
  })
}
```

```{r}
extract_cv_perf <- function(cv) {
  list("train", "test") %>% 
    set_names() %>% 
    imap_dfr(~ {
      cv %>% 
        select(id, all_of(.x)) %>% 
        unnest(all_of(.x)) %>% 
        mutate(partition = .y, .before = everything())
    }) %>% 
    group_by(partition, metric) %>% 
    summarize(mean = mean(value), sd = sd(value), .groups = "drop") %>% 
    pivot_wider(
      id_cols = "metric", 
      names_from = "partition", 
      values_from = c("mean", "sd")
    ) %>% 
    relocate(ends_with("train"), .after = "metric")
}

extract_cv_glance <- function(cv) {
  cv %>% 
    select(id, glance) %>% 
    unnest(glance) %>% 
    pivot_longer(-id, names_to = "metric") %>% 
    group_by(metric) %>% 
    summarize(mean = mean(value), sd = sd(value), .groups = "drop")
}

extract_cv_tidy <- function(cv) {
  cv %>% 
    select(id, tidy) %>% 
    unnest(tidy) %>% 
    arrange(effect, component, group, term, id)
}
```


---

# Data preparation

```{r load_data}
abt_v1 <- vroom::vroom(here("data/abt_prepped.csv")) %>% 
  rename_with(~ str_replace_all(., " ", "."))
```

---

## Feature engineering

### Days since first infection

```{r}
abt_v2 <- abt_v1 %>% 
  group_by(state_code, county_fip) %>% 
  arrange(state_code, county_fip, date) %>% 
  mutate(
    time_days_since_inf1 = suppressWarnings(as.integer(date - min(date[confirmed > 0])))
  ) %>% 
  ungroup() %>% 
  mutate(time_days_since_inf1 = if_else(
    is.na(time_days_since_inf1) | time_days_since_inf1 < 0, 
    -1L, 
    time_days_since_inf1
  ))
```

### Median income

Units of $10K appear meaningful, but this is easy to change.

```{r}
summary(abt_v2$acs_median_hh_inc_total)

abt_v2 <- abt_v2 %>% 
  mutate(
    acs_median_hh_inc_10k = acs_median_hh_inc_total / 10000, 
    .after = acs_median_hh_inc_total
  ) %>% 
  select(-acs_median_hh_inc_total)

summary(abt_v2$acs_median_hh_inc_10k)
```

### Population

We leave population alone for now, but a log transform is certainly possible.

```{r}
summary(abt_v2$acs_pop_total)
```

### Prior day's target

If we want to model day-over-day growth.

```{r}
dim(abt_v2)

abt_v2 <- abt_v2 %>% 
  group_by(state_code, county_fip) %>% 
  arrange(state_code, county_fip, date) %>% 
  mutate(target_lag1 = target - lag(target, 1), .after = target) %>% 
  ungroup() %>% 
  filter(!is.na(target_lag1))

dim(abt_v2)
```


---

## Data reduction for modeling

### Subset features

Subset to specific features:

```{r}
# Named vector renames
keep_columns <- c(
  "date", 
  "state_code", "county_fip", "state", "county", 
  "target", 
  "policy_recoded" = "policy",
  "time_dow", "time_wk_yr",
  "tmpf_mean", "relh_mean", 
  "acs_pop_total",
  "acs_age_le_24", "acs_age_25_34", "acs_age_35_44", "acs_age_45_54", 
  "acs_age_55_64", "acs_age_65_74", "acs_age_75_84", "acs_age_85_ge", 
  "acs_race_minority", 
  "acs_gender_female",
  "acs_median_hh_inc_10k", 
  "cov_pos_tests", "cov_total_tests",
  "mobility_retail_and_recreation" = "retail_and_recreation", 
  "mobility_grocery_and_pharmacy" = "grocery_and_pharmacy", 
  "mobility_parks" = "parks", 
  "mobility_transit_stations" = "transit_stations", 
  "mobility_workplaces" = "workplaces", 
  "mobility_residential" = "residential",
  "time_days_since_inf1"
)

abt_sub <- abt_v2 %>% 
  select(all_of(keep_columns)) %>% 
  mutate(across(c(where(is.character), -c(date:county)), factor))

dim(abt_sub)

abt_sub %>% 
  group_by(county_fip) %>% 
  summarize(nrow = n(), .groups = "drop") %>% 
  summarize(across(nrow, .fns = list(mean = mean, sd = sd)))
```

### Subset rows 

**Important:** We are interested in policy impact on the changing COVID
landscape. So let's not model pre-testing, pre-policy times. Focus on times
_since_ positive cases.

```{r}
abt_sub <- abt_sub %>% filter(time_days_since_inf1 > -1)

# Cuts our rows substantially
dim(abt_sub)

abt_sub %>% 
  group_by(county_fip) %>% 
  summarize(nrow = n(), .groups = "drop") %>% 
  summarize(across(nrow, .fns = list(mean = mean, sd = sd)))
```

Still plenty of zeroes:

```{r}
abt_sub %>% 
  ggplot(aes(target)) + 
  geom_histogram(bins = 50) + 
  scale_y_log10()
```

---

## Feature standardization

```{r}
# Make a standardization table
std_table <- abt_sub %>% 
  select(-c(date:target)) %>% 
  select(where(is.numeric)) %>% 
  map_dfr(~ tibble(mean = mean(.x), sd = sd(.x)), .id = "feature")
```

```{r}
# Apply the table
abt_sub_std <- abt_sub %>% 
  mutate(across(
    all_of(std_table$feature), ~ 
      (. - std_table[std_table$feature == cur_column(), ]$mean) /
      std_table[std_table$feature == cur_column(), ]$sd
  ))
```

---

## Data sample for development

To keep development snappy, take 10 counties per state for 10 states. (Yes, this
is biased, but it allows for several kinds of useful tests.)

```{r}
set.seed(RANDOM_SEED)

sample_ids <- abt_sub_std %>% 
  group_by(state, state_code) %>% 
  summarize(n_counties = n_distinct(county_fip), .groups = "drop") %>% 
  filter(n_counties > 20) %>% 
  sample_n(10) %>% 
  left_join(abt_sub_std, by = c("state", "state_code")) %>% 
  distinct(state, state_code, county, county_fip) %>% 
  group_by(state_code) %>% 
  sample_n(10) %>% 
  ungroup()

sample_abt <- abt_sub_std %>% 
  semi_join(sample_ids, by = c("state", "state_code", "county", "county_fip"))

dim(sample_abt)
```

---

# Feature testing

Test features using the development subset.

## Correlations

 - [x] Bug in our minority feature
 - Days since infection tracks week of the year, as you'd expect
   - Keep days since infection?
 - Collapse into larger age bins?
 - Unclear about the mobility; the correlations are lesser

```{r, fig.width=8, fig.height=8}
correlations <- abt_sub_std %>% 
  select(-c(date:county)) %>% 
  select(where(is.numeric)) %>% 
  cor()

correlations %>% 
  as_tibble(rownames = "feature1") %>% 
  pivot_longer(-feature1, names_to = "feature2", values_to = "correlation") %>% 
  filter(abs(correlation) > 0.6) %>% 
  filter(feature1 < feature2) %>% 
  arrange(-abs(correlation))

corrplot::corrplot(
  correlations, 
  method = "color", 
  order = "hclust", 
  tl.col = "black", 
  tl.cex = 0.8
)
```

---

## Boruta

Run Boruta against the full sample data. Boruta runs permutation tests against
the input features using Random Forests to identify all _relevant_ features.

```{r}
save_path <- here("data/ts_boruta_sample.rds")

if (!file.exists(save_path)) {
  cat("Re-running Boruta\n")
  bb <- sample_abt %>% 
    select(-c(date:county)) %>% 
    Boruta::Boruta(target ~ ., data = ., maxRuns = 50, doTrace = 2)
  saveRDS(bb, save_path)
}

bb <- readRDS(save_path)
```

NB: 

 - `time_dow` is rejected
 - Now that we start on infection "day zero," some of our feature 
   importance have changed

```{r}
# Make a nicer Boruta importance history plot that lists all column names
bb$ImpHistory %>% 
  as_tibble(rownames = "iteration") %>% 
  pivot_longer(-iteration, names_to = "feature", values_to = "importance") %>% 
  filter(importance > -Inf) %>% 
  left_join(enframe(bb$finalDecision, "feature", "decision"), by = "feature") %>% 
  mutate(feature = fct_rev(fct_reorder(factor(feature), importance, median))) %>% 
  ggplot(aes(feature, importance, fill = decision)) + 
  geom_boxplot() + 
  coord_flip() + 
  scale_fill_manual(na.translate = F, values = c("#00cc66", "#9966ff"))
``` 

---

## Univariate target associations

For each feature in our data, how well does it help fits? 
How well does it fit held out data? 
What are its standalone parameter estimates?

### Plots

Numerics:

```{r, fig.height=8, fig.width=10}
sample_abt %>% 
  select(-c(date:county)) %>% 
  select(target, where(is.numeric)) %>% 
  pivot_longer(-target) %>% 
  ggplot(aes(value, target)) + 
  geom_smooth(size = 0.5) + 
  facet_wrap(~ name, scales = "free_x") + 
  theme(aspect.ratio = 9 / 16)
```

Factors:

```{r}
sample_abt %>% 
  select(-c(date:county)) %>% 
  select(target, where(is.factor)) %>% 
  pivot_longer(-target) %>% 
  ggplot(aes(value, target)) + 
  geom_boxplot(outlier.shape = NA) + 
  facet_wrap(~ name, scales = "free_x") + 
  ylim(0, 40)
```

---

## Multivariate target associations

For seemingly useful feature sets in our data, how well do they help fits? 
How well do they fit held out data? 
What are its standalone parameter estimates?

### Age and economic status

```{r}
sample_abt %>% 
  select(target, acs_median_hh_inc_10k, starts_with("acs_age")) %>% 
  glm(target ~ acs_median_hh_inc_10k*(
      acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
      acs_age_65_74 + acs_age_75_84 + acs_age_85_ge
    ), family = poisson(), data = .) %>% 
  summary()
```

### Economic and minority status

```{r}
sample_abt %>% 
  select(target, acs_median_hh_inc_10k, acs_race_minority) %>% 
  glm(
    target ~  acs_median_hh_inc_10k*acs_race_minority, 
    family = poisson(), 
    data = .
  ) %>% 
  summary()
```

---

# Model building

We use a zero-inflated negative-binomial model. (Update: in this scheme we
don't need zero inflation.) Add features, testing CV performance as we go.

---

## Initial random intercepts baseline model

```{r}
save_path <- here("data/ts_model_baseline.rds")

if (!file.exists(save_path)) {
  cat("Running model\n")
  
  baseline <- run_model_vfold(
    formula = target ~ 1 + (1 | state_code/county_fip),
    data = sample_abt, 
    ziformula = ~ 1
  )
  saveRDS(baseline, save_path)
}

baseline <- readRDS(save_path)
```

```{r}
baseline %>% extract_cv_glance()
baseline %>% extract_cv_perf()
```

### Without zero inflation

```{r}
save_path <- here("data/ts_model_baseline_nozi.rds")

if (!file.exists(save_path)) {
  cat("Running model\n")
  
  baseline_nozi <- run_model_vfold(
    formula = target ~ 1 + (1 | state_code/county_fip),
    data = sample_abt
  )
  saveRDS(baseline_nozi, save_path)
}

baseline_nozi <- readRDS(save_path)
```

Little difference in performance.

```{r}
baseline_nozi %>% extract_cv_glance()
baseline_nozi %>% extract_cv_perf()
```

---

## Larger models

Build a sequence of larger models, measuring fit and OOS performance.
This will give a rough idea of allowable model complexity, which we can
then fine tune.
NB: Each model is saved for later reuse.

```{r}
larger_model_formulae <- list(
  "larger_dem_pop_test" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_polrs" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    (1 + policy_recoded | state_code) + 
    (1 | state_code:county_fip),
  
  "larger_dem_pop_test_mob" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip_id" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    policy_recoded:mobility_workplaces + 
    policy_recoded:mobility_grocery_and_pharmacy + 
    policy_recoded:mobility_transit_stations + 
    policy_recoded:mobility_residential + 
    acs_pop_total:acs_median_hh_inc_10k + 
    acs_race_minority:acs_median_hh_inc_10k + 
    acs_pop_total:acs_race_minority + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip_id_im" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    acs_pop_total:acs_median_hh_inc_10k + 
    acs_race_minority:acs_median_hh_inc_10k + 
    acs_pop_total:acs_race_minority + 
    policy_recoded:mobility_workplaces + 
    policy_recoded:mobility_grocery_and_pharmacy + 
    policy_recoded:mobility_transit_stations + 
    policy_recoded:mobility_residential + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip_id_ia" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    acs_pop_total:acs_median_hh_inc_10k + 
    acs_race_minority:acs_median_hh_inc_10k + 
    acs_pop_total:acs_race_minority + 
    policy_recoded:(acs_age_65_74 + acs_age_75_84 + acs_age_85_ge) + 
    acs_median_hh_inc_10k:(acs_age_65_74 + acs_age_75_84 + acs_age_85_ge) + 
    acs_race_minority: (acs_age_65_74 + acs_age_75_84 + acs_age_85_ge) +
    (1 | state_code/county_fip)
)
```

```{r}
# These run serially, but the CV is parallelized
iwalk(larger_model_formulae, ~ {
  save_path <- here(glue("data/ts_model_{.y}.rds"))

  if (!file.exists(save_path)) {
    cat(glue("Running model {.y}"), "\n\n")
    
    model <- run_model_vfold(
      formula = .x,
      data = sample_abt
    )
    saveRDS(model, save_path)
  }
})
```

```{r}
larger_models <- larger_model_formulae %>% 
  imap(~ readRDS(here(glue("data/ts_model_{.y}.rds"))))
```

### Model performance measures

### AIC, BIC, etc

Hard to say anything based on BIC. These models are difficult.

```{r}
larger_models %>% 
  imap_dfr(~ {
    .x %>% 
      select(glance) %>% 
      unnest(glance)
  }, .id = "model") %>% 
  select(-sigma) %>% 
  group_by(model) %>% 
  summarize(across(.fns = list(mean = mean, sd = sd)), .groups = "drop")
```

### Train vs test performance

Again, hard to say these (very large) models are overfit. 
Very larger error bars.

```{r}
larger_models %>% 
  map_dfr(extract_cv_perf, .id = "model") %>% 
  pivot_longer(
    mean_train:sd_test, 
    names_to = c("measure", "partition"), 
    names_sep = "_"
  ) %>% 
  pivot_wider(names_from = "measure") %>% 
  ggplot(aes(model, mean, color = partition)) + 
  geom_point(alpha = 0.5) + 
  geom_errorbar(
    aes(ymin = mean - sd, ymax = mean + sd), 
    size = 0.5, width = 0, alpha = 0.5
  ) + 
  facet_wrap(~ metric, scales = "free_x") + 
  coord_flip()
```

### Model visualization

```{r, echo=F}
# Visualize the fixed effects for 1 CV fold
iwalk(larger_models, ~ print(plot_model(.x$object[[1]], title = .y, type = "est")))
# iwalk(larger_models, ~ print(plot_model(.x$object[[1]], title = .y, type = "re")))
```

---

## Handle correlations

### Decorrelate COVID tests

```{r}
sample_abt %>% 
  mutate(cov_pos_tests = cov_pos_tests / cov_total_tests) %>% 
  with(cor(cov_pos_tests, cov_total_tests))

sample_abt <- sample_abt %>% 
  mutate(
    cov_pos_tests_frac = cov_pos_tests / cov_total_tests,
    (cov_pos_tests_frac - mean(cov_pos_tests_frac)) / sd(cov_pos_tests_frac)
  )
```

```{r}
save_path <- here(glue("data/ts_model_larger_dem_pop_test_covfrac.rds"))

if (!file.exists(save_path)) {
  cat(glue("Running model larger_dem_pop_test_covfrac"), "\n\n")
  
  # Same model as before, with a different covid pos test var
  model <- run_model_vfold(
    formula = target ~ 1 + 
      time_days_since_inf1 + 
      # Demographics
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
      acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
      # Policy
      policy_recoded + 
      # Testing
      cov_pos_tests_frac + cov_total_tests + 
      (1 | state_code/county_fip),
    data = sample_abt
  )
  
  saveRDS(model, save_path)
}

larger_dem_pop_test_covfrac <- readRDS(save_path)
```

It isn't clear that removing this correlation helps.

```{r}
larger_dem_pop_test_covfrac %>% 
  extract_cv_perf()

larger_models[["larger_dem_pop_test"]] %>% 
  extract_cv_perf()
```

### Age binning

From correlation analysis, we should reduce the number of age bins.
Do this and test the impact on one of our models above.

```{r}

```

---

# Residual analysis

Start from the model and look at transformations.


```{r, include=F, echo=F}
# Shut down multisession
plan(sequential)
```
