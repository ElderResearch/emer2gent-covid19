---
title:  "Regression Model Development"
author: "Tom Shafer"
date:   "2020-06-11, updated 2020-06-13"
output: html_document
---

```{r setup, include=FALSE}
r_root <- rprojroot::find_rstudio_root_file()

knitr::opts_knit$set(root.dir = file.path(r_root))
knitr::opts_chunk$set(warning = FALSE, message = FALSE, dpi = 100)
knitr::opts_chunk$set(fig.width = 8, fig.height = 8)

ggplot2::theme_set(ggplot2::theme_minimal())
```

```{r init}
options(stringsAsFactors = F)

suppressPackageStartupMessages({
  library(tidyverse)
  library(here)
  library(rsample)
  library(glmmTMB)
  library(sjPlot)
  library(furrr)
  library(broom.mixed)
  library(yardstick)
  library(glue)
})

plan(multiprocess)
```


# Overview

## Objectives 

- [x] Generate data sample
- [x] Do not use pop weighting
- [x] Do feature engineering
- [x] Do basic feature selection
- [x] V-fold CV for evaluation
- [x] Better standardization
- [x] Collapse ages
- [x] Select down mobility data
- [x] Bigger CV sample
- [x] Add econ data
- [x] Look at trajectories
- [ ] Add deltas
- [ ] Add restriction loosening
- [ ] Add day-of-week encoding
- [ ] Add time since first retriction

- [x] Choose features
- [ ] Do residual analysis
- [ ] Add fittable covariate lag factor
- [ ] Add median age variable instead of age bins? Or in addition to?
- [x] add policy as a random slope (didn't work)
- [x] Do we want to exclude initial zeros?

## Results

- Negative-binomial model
- No zero inflation for now, having excluded many zeros
- Interacting time with policy is important
- Unclear if we should include economic data, small effects and 
  potential for confounding
- Unclear if we should include mobility data, large effect and helps to fit 
  but seems to confound policy

We might fit two models, one with random slopes and one without.
We should also look at how the policy coefficients move around with 
cofactors, especially if the cofactors do not change OOS performance.

---

# Setup and helper functions

Set `FORCE_MODEL_RUN <- TRUE` to re-run all calculations, 
even if a cached version is available.

```{r}
RANDOM_SEED <- -461698
FORCE_MODEL_RUN <- FALSE

source(here("R/helpers.R"))
```

---

# Data preparation

```{r load_data}
abt_v1 <- vroom::vroom(here("data/abt_prepped.csv"))
```

## Feature engineering

### Days since first infection

```{r}
abt_v2 <- abt_fe_time_days_since_inf1(abt_v1)
summary(abt_v2$time_days_since_inf1)
```

### Median income

Units of $10K appear meaningful, but this is easy to change.

```{r}
summary(abt_v2$acs_median_hh_inc_total)
abt_v2 <- abt_fe_acs_median_hh_inc_10k(abt_v2)
summary(abt_v2$acs_median_hh_inc_10k)
```

---

## Data reduction for modeling

### Subset features

Subset to specific features:

```{r}
# Named vector components renames as well as choose
keep_columns <- c(
  "date", 
  "state_code", "county_fip", "state", "county", 
  "target", 
  "policy_recoded" = "policy",
  "time_dow", "time_wk_yr", "time_days_since_inf1",
  "tmpf_mean", "relh_mean", 
  "pop_density", "acs_pop_total",
  "acs_age_le_24", "acs_age_25_34", "acs_age_35_44", "acs_age_45_54", 
  "acs_age_55_64", "acs_age_65_74", "acs_age_75_84", "acs_age_85_ge", 
  "acs_race_minority", 
  "acs_gender_female",
  "acs_median_hh_inc_10k", 
  "cov_pos_tests", "cov_total_tests",
  "mobility_retail_and_recreation" = "retail_and_recreation", 
  "mobility_grocery_and_pharmacy" = "grocery_and_pharmacy", 
  "mobility_parks" = "parks", 
  "mobility_transit_stations" = "transit_stations", 
  "mobility_workplaces" = "workplaces", 
  "mobility_residential" = "residential",
  "labor_force", "unemployed"
)

# Strings to factors in certain cases
abt_sub <- abt_v2 %>% 
  select(all_of(keep_columns)) %>% 
  mutate(across(c(where(is.character), -c(date:county)), factor))

dim(abt_sub)

abt_sub %>% 
  group_by(county_fip) %>% 
  summarize(nrow = n(), .groups = "drop") %>% 
  summarize(across(nrow, .fns = list(mean = mean, sd = sd)))

colSums(is.na(abt_sub))
```

### Subset rows 

**Important:** We are interested in policy impact on the changing COVID
landscape. So let's not model pre-testing, pre-policy times. Focus on times
_since_ positive cases.

```{r}
abt_sub <- abt_sub %>% filter(time_days_since_inf1 > -1)

# Cuts our rows substantially
dim(abt_sub)

abt_sub %>% 
  group_by(county_fip) %>% 
  summarize(nrow = n(), .groups = "drop") %>% 
  summarize(across(nrow, .fns = list(mean = mean, sd = sd)))
```

Still plenty of zeroes:

```{r}
abt_sub %>% 
  ggplot(aes(target)) + 
  geom_histogram(bins = 50) + 
  scale_y_log10()
```

---

## Simple feature standardization

 - Fractions -> percentages
 - Other continuous features -> standardized

```{r}
std_vars <- c(
  "tmpf_mean", "relh_mean", 
  "pop_density", 
  "acs_pop_total", "acs_median_hh_inc_10k", 
  "cov_pos_tests", "cov_total_tests"
)

frac_vars <- c(
  "acs_age_le_24", "acs_age_25_34", "acs_age_35_44", 
  "acs_age_45_54", "acs_age_55_64", "acs_age_65_74", 
  "acs_age_75_84", "acs_age_85_ge", "acs_race_minority", 
  "acs_gender_female",
  "labor_force", "unemployed"
)

std_table <- abt_sub %>% 
  select(all_of(std_vars)) %>% 
  map_dfr(~ tibble(mean = mean(.x), sd = sd(.x)), .id = "feature")
```

```{r}
# Apply the normalization
abt_sub_std <- abt_sub %>% 
  mutate(across(
    all_of(std_table$feature), ~ 
      (. - std_table[std_table$feature == cur_column(), ]$mean) /
      std_table[std_table$feature == cur_column(), ]$sd
  ))

# NB: models fit better as fractions
# abt_sub_std <- abt_sub_std %>% 
#   mutate(across(all_of(frac_vars), ~ 100 * .))
```

---

# Feature testing

Test features using the development subset.

## Boruta

Run Boruta against a large random sample of 20,000 rows.
We sample entire per-county trajectories ratehr than arbitrary random rows.
Boruta runs permutation tests against the input features using Random 
Forests to identify all _relevant_ features.

```{r}
bb <- cache_operation(here("data/ts_boruta_sample.rds"), {
  set.seed(RANDOM_SEED)
  bt_sub_std %>% 
    distinct(county_fip) %>% 
    sample_n(275) %>% 
    semi_join(abt_sub_std, ., by = "county_fip") %>% 
    select(-c(date:county)) %>% 
    Boruta::Boruta(target ~ ., data = ., maxRuns = 20, doTrace = 2)
})
```

Boruta results:

 - `time_dow` is rejected
 - Feature importance looks different now that we start on infection "day zero"

```{r}
# Make a nicer Boruta importance history plot that lists all column names
plot_boruta(bb)
``` 

---

## Correlations

 - Days since infection tracks week of the year, as you'd expect
   - Outcome: Do not use week of year
 - Age bins are quite correlated
   - Collapse older age bins together
   - Leave oldest bin separated (cf. nursing home outbreaks)
   - Drop ages < 24 from analysis to prevent model fit issues
 - Mobility is self-correlated, but at a lesser strength.
   - Cf. Mike and consider two elements: workplace and retail

```{r, fig.width=8, fig.height=8}
correlations <- abt_sub_std %>% 
  select(-c(date:county)) %>% 
  select(where(is.numeric)) %>% 
  cor()

correlations %>% 
  as_tibble(rownames = "feature1") %>% 
  pivot_longer(-feature1, names_to = "feature2", values_to = "correlation") %>% 
  # filter(feature1 == "pop_density") %>%
  filter(abs(correlation) > 0.6) %>% 
  filter(feature1 < feature2) %>% 
  arrange(-abs(correlation)) %>% 
  print(n = Inf)

corrplot::corrplot(
  correlations, 
  method = "color", 
  order = "hclust", 
  tl.col = "black", 
  tl.cex = 0.8
)
```

### Treat correlated features

#### COVID tests

Simple percentage normalization takes care of the correlation:

```{r}
abt_sub_std %>% 
  mutate(cov_pos_tests = 100 * cov_pos_tests / cov_total_tests) %>% 
  with(cor(cov_pos_tests, cov_total_tests))
```

Using the Boruta results, we include the most "important" features and then
look at the impact of changing our COVID testing parameterization.

```{r}
set.seed(RANDOM_SEED)

m1_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests + cov_total_tests + 
      (1|state_code/county_fip), 
    data = .
  )

set.seed(RANDOM_SEED)

m2_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  mutate(cov_pos_tests = cov_pos_tests / cov_total_tests) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests + cov_total_tests + 
      (1|state_code/county_fip), 
    data = .
  )

# No major difference, so OK to change.
bind_rows(
  glance(m1_) %>% mutate(model = "original", .before = everything()),
  glance(m2_) %>% mutate(model = "new", .before = everything())
)
```

Implement the change:

```{r}
abt_sub <- abt_fe_add_cov_pos_tests_frac(abt_sub)

# Cannot apply to standardized features directly
std_pars_p <- std_table[std_table$feature == "cov_pos_tests", ]
std_pars_t <- std_table[std_table$feature == "cov_total_tests", ]
abt_sub_std <- abt_sub_std %>% 
  mutate(
    cov_pos_tests = cov_pos_tests * std_pars_p$sd + std_pars_p$mean,
    cov_total_tests = cov_total_tests * std_pars_t$sd + std_pars_t$mean
  ) %>% 
  abt_fe_add_cov_pos_tests_frac() %>% 
  mutate(across(c(cov_pos_tests, cov_total_tests), ~ (. - mean(.)) / sd(.)))
```

#### Age binning

Based on the correlation analysis we should reduce the number of age bins.
Then carry out a similar test as above.

```{r}
# This deals with r > 0.7 (dropping ages le 24, which will roll into the intercept)
abt_sub_std %>% 
  mutate(
    acs_age_25_54 = acs_age_25_34 + acs_age_35_44 + acs_age_45_54,
    acs_age_55_84 = acs_age_55_64 + acs_age_65_74 + acs_age_75_84,
    .keep = "unused"
  ) %>%
  select(starts_with("acs_age")) %>% 
  cor()
```

Test the modeling impact:

```{r}
set.seed(RANDOM_SEED)

m1_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + 
      cov_total_tests + 
      acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + 
      acs_age_55_64 + acs_age_65_74 + acs_age_75_84 + acs_age_85_ge +
      (1 | state_code/county_fip), 
    data = .
  )

set.seed(RANDOM_SEED)

m2_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  mutate(
    acs_age_25_54 = acs_age_25_34 + acs_age_35_44 + acs_age_45_54,
    acs_age_55_84 = acs_age_55_64 + acs_age_65_74 + acs_age_75_84,
    .keep = "unused"
  ) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + cov_total_tests + 
      acs_age_25_54 + acs_age_55_84 + acs_age_85_ge +
      (1 | state_code/county_fip), 
    data = .
  )

# No major difference, so OK to change.
bind_rows(
  glance(m1_) %>% mutate(model = "original", .before = everything()),
  glance(m2_) %>% mutate(model = "new", .before = everything())
)
```

Implement the change:

```{r}
abt_sub_std <- abt_fe_add_coarse_age_bins(abt_sub_std)
abt_sub <- abt_fe_add_coarse_age_bins(abt_sub)
```

#### Mobility subsets

Check the mobility correlations:

```{r}
# This agrees with Mike's notion that retail & rec and workplaces covers it
abt_sub_std %>% 
  select(starts_with("mobility")) %>% 
  cor() %>% 
  as_tibble(rownames = "item1") %>% 
  pivot_longer(-item1, "item2") %>% 
  filter(item1 < item2) %>% 
  arrange(-abs(value))
```

Test the effect of only including two features:

```{r}
set.seed(RANDOM_SEED)

m1_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + 
      cov_total_tests + 
      mobility_retail_and_recreation + mobility_grocery_and_pharmacy + 
      mobility_parks + mobility_transit_stations + 
      mobility_workplaces + mobility_residential + 
      (1 | state_code/county_fip), 
    data = .
  )

set.seed(RANDOM_SEED)

m2_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + 
      cov_total_tests + 
      mobility_retail_and_recreation + mobility_workplaces + 
      (1 | state_code/county_fip), 
    data = .
  )

# No major difference, so OK to change.
bind_rows(
  glance(m1_) %>% mutate(model = "original", .before = everything()),
  glance(m2_) %>% mutate(model = "new", .before = everything())
)
```

(No change to implement.)

---

## Univariate target associations

For each feature in our data, how well does it help fits? 
How well does it fit held out data? 
What are its standalone parameter estimates?

Numerics:

```{r, fig.height=8, fig.width=10}
set.seed(RANDOM_SEED)
abt_sub_std %>% 
  sample_n(10000) %>% 
  select(-c(date:county), state_code) %>% 
  select(target, state_code, where(is.numeric)) %>% 
  mutate(target_scaled = target / acs_pop_total) %>% 
  pivot_longer(-c(target, target_scaled, state_code)) %>% 
  ggplot(aes(value, target, group = state_code)) + 
  geom_smooth(method = "glm", size = 0.5, alpha = 0.5) + 
  facet_wrap(~ name, scales = "free_x") + 
  theme(aspect.ratio = 9 / 16) + 
  labs(title = "Per-state glm")


set.seed(RANDOM_SEED)
abt_sub_std %>% 
  sample_n(10000) %>% 
  select(-c(date:county), state_code) %>% 
  select(target, state_code, where(is.numeric)) %>% 
  mutate(target_scaled = target / acs_pop_total) %>% 
  pivot_longer(-c(target, target_scaled, state_code)) %>% 
  ggplot(aes(value, target)) + 
  geom_smooth(size = 0.5, alpha = 0.5) + 
  facet_wrap(~ name, scales = "free_x") + 
  theme(aspect.ratio = 9 / 16) + 
  labs(title = "Total")
```

Factors:

```{r}
set.seed(RANDOM_SEED)
abt_sub_std %>% 
  sample_n(10000) %>% 
  select(-c(date:county)) %>% 
  select(target, where(is.factor)) %>% 
  pivot_longer(-target) %>% 
  ggplot(aes(value, target)) + 
  geom_boxplot(outlier.shape = NA) + 
  facet_wrap(~ name, scales = "free_x") + 
  ylim(0, 40)
```

We'll tackle interactions during modeling.

---

# Data samples for development

## Sample 2: 40 counties by 25 states

Re-standardize, etc.

 - <http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf>
 - Statistical rethinking, ch 5
 
```{r}
set.seed(RANDOM_SEED)

sample2_ids <- abt_sub %>% 
  group_by(state, state_code) %>% 
  summarize(n_counties = n_distinct(county_fip), .groups = "drop") %>% 
  filter(n_counties > 40) %>% 
  sample_n(25) %>% 
  left_join(abt_sub_std, by = c("state", "state_code")) %>% 
  distinct(state, state_code, county, county_fip) %>% 
  group_by(state_code) %>% 
  sample_n(40) %>% 
  ungroup()

sample2_abt <- abt_sub %>% 
  semi_join(sample2_ids, by = c("state", "state_code", "county", "county_fip"))

dim(sample2_abt)
summary(sample2_abt)
```

Check distributions:

 - Fix pop. and pop. density skew with a log
 - Fix all ACS with skew using log
 - Fix COVID-19 testing using log(1+x)

```{r}
sample2_abt %>%
  mutate(across(c(pop_density, starts_with("acs")), log)) %>% 
  mutate(across(starts_with("cov"), log1p)) %>% 
  select(where(is.numeric), -county_fip) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(value)) + 
  geom_histogram(bins = 50) + 
  facet_wrap(~ name, scales = "free")
```
 
 Remove variables we plan not to use.
 The target is OK because we're modeling as a negative binomial.
 NB: We might be introducing a bit of bias by doing this scaling outside of CV.

```{r}
sample2_abt <- sample2_abt %>% 
  mutate(
    across(c(pop_density, starts_with("acs")), log),
    across(starts_with("cov"), log1p)
  ) %>% 
  select(-c(
    time_wk_yr, 
    acs_age_25_34:acs_age_75_84,
    mobility_grocery_and_pharmacy, mobility_transit_stations, mobility_residential
  )) %>% 
  # circle-encode day of week
  mutate(
    time_dow_x = cos(2 * pi * (as.integer(time_dow) - 1) / 7),
    time_dow_y = sin(2 * pi * (as.integer(time_dow) - 1) / 7),
    .keep = "unused",
    .after = "time_dow"
  ) %>% 
  mutate(time_log = log1p(time_days_since_inf1)) %>% 
  # standardize
  mutate(across(time_dow_x:time_log, ~ (. - mean(.)) / (2 * sd(.))))

dim(sample2_abt)
summary(sample2_abt)
```

```{r}
sample2_abt %>% 
  select(where(is.numeric), -county_fip) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(value)) + 
  geom_histogram(bins = 50) + 
  facet_wrap(~ name, scales = "free")
```

---

# Model building: Sample 2

Similar tests, but with a larger sample.

We also start from policy and add features that (1) help prediction and 
(2) might help with policy inference.

---

## 0. Policy-only baseline

This is the baseline; it won't be good.

```{r}
s2_pol_bl <- cache_operation(
  here("data/ts_model_s2_pol_bl.rds"), {
    run_model_vfold(
     formula = target ~ 1 + policy_recoded + (1 | state_code/county_fip),
     data = sample2_abt, 
     seed = RANDOM_SEED
    )
})
```

### Stats tables

```{r}
s2_pol_bl %>% extract_cv_glance()
s2_pol_bl %>% extract_cv_perf()
s2_pol_bl %>% extract_cv_tidy()
```

### Fit charts

```{r}
plot_models(s2_pol_bl$object)
plot_model(s2_pol_bl$object[[1]], type = "resid")
plot_model(s2_pol_bl$object[[1]], type = "diag")
```

```{r}
plot_model(s2_pol_bl$object[[1]], type = "re")
```

### Trajectory plots

Sample a few counties, two from each fold, and plot predictions.
Note that the fits are OK, but the directionality makes no sense because
we are missing many covariates (the above residual plot makes sens, though).

```{r}
s2_pol_bl %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 1. Introduce key covariates

New covariates:

 - Time since first reported infection
 - Day of the week
 - Population and population density
 - Demographics
 - COVID-19 testing

```{r}
FORCE_MODEL_RUN <- 0
s2_pol_cov <- cache_operation(
  here("data/ts_model_s2_pol_kcov.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       time_dow_x + time_dow_y + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

This helps tremendously, with $R^2 = 0.65(15)$ on held out data.

```{r}
extract_cv_glance(s2_pol_bl, s2_pol_cov)
extract_cv_perf(s2_pol_bl, s2_pol_cov)

s2_pol_cov %>% extract_cv_tidy()
```

### Fit charts

 - Results are consistent
 - Right now, all policies are mainly correlated with rising cases, which
   really suggests we haven't captured the effects yet
 - Day of week doesn't help

```{r}
plot_models(s2_pol_cov$object, dot.size = 2)
plot_model(s2_pol_cov$object[[1]], type = "resid")
plot_model(s2_pol_cov$object[[1]], type = "diag")
```

```{r}
plot_model(s2_pol_cov$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 2. Policy with economics

**NB:** This was without pop_density.

```{r}
s2_pol_cov1_econ <- here("data/ts_model_s2_pol_cov_econ.rds") %>%
  cache_operation({
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       labor_force + unemployed + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

```{r}
# Compare to models without time interactions, to be on equal footing
extract_cv_glance(s2_pol_cov1_econ, s2_pol_cov)
extract_cv_perf(s2_pol_cov1_econ, s2_pol_cov)

# Very small effects
s2_pol_cov1_econ %>% 
  extract_cv_tidy()
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_econ$object, dot.size = 2)

plot_model(s2_pol_cov1_econ$object[[1]], type = "diag")
plot_model(s2_pol_cov1_econ$object[[1]], type = "resid")
```

```{r}
plot_model(s2_pol_cov1_econ$object[[1]], type = "re")
```

```{r}
fixef(s2_pol_cov1_econ$object[[1]]) %>% as_vector() %>% enframe()
ranef(s2_pol_cov1_econ$object[[1]]) %>% as_tibble()
```

### Trajectory plots

```{r}
s2_pol_cov1_econ %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 3. Policy with mobility

```{r}
s2_pol_cov1_econ_mob <- here("data/ts_model_s2_pol_cov_econ_mob.rds") %>%
  cache_operation({
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       labor_force + unemployed + 
       mobility_retail_and_recreation + mobility_workplaces + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

```{r}
# Compare to models without time interactions, to be on equal footing
extract_cv_glance(s2_pol_cov1_econ_mob, s2_pol_cov)
extract_cv_perf(s2_pol_cov1_econ_mob, s2_pol_cov)

# Very small effects
s2_pol_cov1_econ_mob %>% extract_cv_tidy()
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_econ_mob$object, dot.size = 2)

# Only look at 1st CV fold
plot_model(s2_pol_cov1_econ_mob$object[[1]], type = "diag")
plot_model(s2_pol_cov1_econ_mob$object[[1]], type = "resid")
```

```{r}
# Only look at 1st CV fold
plot_model(s2_pol_cov1_econ_mob$object[[1]], type = "re")
```

```{r}
# Only look at 1st CV fold
fixef(s2_pol_cov1_econ_mob$object[[1]]) %>% as_vector() %>% enframe()
ranef(s2_pol_cov1_econ_mob$object[[1]]) %>% as_tibble()
```

### Trajectory plots

```{r}
s2_pol_cov1_econ_mob %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 4. Policy-time interactions

Allow policy to interact with time through a term

$$
\frac{\partial^2 y}{\partial t \partial p} = 
  \frac{\partial}{\partial p}\frac{\partial y}{\partial t}
$$
that attempts to capture how the rate of progression changes with policy.

**NB:* This was run before pop. density or day of week were included.

```{r}
s2_pol_cov1_it <-  cache_operation(
  here("data/ts_model_s2_pol_kcov_it_200613.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       # This is the new interaction
       policy_recoded:time_days_since_inf1 + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

No clear harm to the model fit, but no real imprevent either.

```{r}
extract_cv_glance(s2_pol_cov, s2_pol_cov1_it)
extract_cv_perf(s2_pol_cov, s2_pol_cov1_it)

s2_pol_cov1_it %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_it$object, dot.size = 2)
```

```{r}
# CV fold 1 only
plot_model(s2_pol_cov1_it$object[[1]], type = "diag")
plot_model(s2_pol_cov1_it$object[[1]], type = "resid")
plot_model(s2_pol_cov1_it$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov1_it %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 5. More time interactions

We ask whether race, income, or pop. density affect the trajectory.

```{r}
s2_pol_cov1_it2 <- cache_operation(here("data/ts_model_s2_pol_simpler_it.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       policy_recoded:time_days_since_inf1 + 
       # These are the new interactions
       acs_median_hh_inc_10k:time_days_since_inf1 + 
       acs_race_minority:time_days_since_inf1 + 
       pop_density:time_days_since_inf1 + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

Out-of-sample we are marginally, but nowhere near significantly, better.

```{r}
extract_cv_glance(s2_pol_cov1_it2, s2_pol_cov1_it)
extract_cv_perf(s2_pol_cov1_it2, s2_pol_cov1_it)

s2_pol_cov1_it2 %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_it2$object, dot.size = 2)

plot_model(s2_pol_cov1_it2$object[[1]], type = "diag")
plot_model(s2_pol_cov1_it2$object[[1]], type = "resid")
```

```{r}
plot_model(s2_pol_cov1_it2$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov1_it2 %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 6. Random slopes with time

**NB:** A model with random slope interactions didn't converge.

```{r}
s2_pol_simpler_rt <- here("data/ts_model_s2_pol_simpler_rt_200613.rds") %>%
  cache_operation({
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + 
       acs_race_minority + 
       acs_gender_female +
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge +
       cov_total_tests + cov_pos_tests_frac + 
       policy_recoded:time_days_since_inf1 + 
       (1 + time_days_since_inf1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

Massive improvement in model fit metrics, and reasonable improvement
in out-of-sample metrics,.

```{r}
extract_cv_glance(s2_pol_simpler_rt, s2_pol_cov1_it)
extract_cv_perf(s2_pol_simpler_rt, s2_pol_cov1_it)

s2_pol_simpler_rt %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_simpler_rt$object, dot.size = 2)
```

```{r}
# Only looking at CV fold 1
plot_model(s2_pol_simpler_rt$object[[1]], type = "diag")
plot_model(s2_pol_simpler_rt$object[[1]], type = "resid")
plot_model(s2_pol_simpler_rt$object[[1]], type = "re")
```

```{r}
fixef(s2_pol_simpler_rt$object[[1]]) %>% as_vector() %>% enframe()
ranef(s2_pol_simpler_rt$object[[1]]) %>% as_tibble()
```

### Trajectory plots

```{r}
s2_pol_simpler_rt %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 7. For Carlos: No population

```{r}
s2_pol_cov_nopop <- cache_operation(
  here("data/ts_model_s2_pol_kcov_nopop.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       time_dow_x + time_dow_y + 
       pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

- No big changes in fit stats, except that the across-fold SD drops way down.
- The nopop model has worse out-of-sample accuracy b/c we've elimintated
  a shared effect that goes into the model.

```{r}
# Compare to sibling model
extract_cv_glance(s2_pol_cov, s2_pol_cov_nopop)
extract_cv_perf(s2_pol_cov, s2_pol_cov_nopop)
```

```{r}
# Comparison plots
extract_cv_perf(s2_pol_cov, s2_pol_cov_nopop) %>% 
  pivot_longer(mean_train:sd_test, names_to = c("measure", "part"), names_sep = "_") %>%
  pivot_wider(names_from = "measure") %>% 
  mutate(
    part = factor(
      if_else(part == "train", "Train", "Test"), 
      levels = c("Train", "Test")
    ),
    metric = case_when(
      metric %in% c("ccc", "mae") ~ str_to_upper(metric),
      metric == "rsq" ~ "R-squared",
      TRUE ~ str_to_title(metric)
    ),
    model = if_else(model == "s2_pol_cov", "With pop.", "Without pop.")
  ) %>% 
  ggplot(aes(part, mean, color = model)) + 
  geom_point(position = position_dodge(width = 0.2)) + 
  geom_errorbar(
    aes(ymin = mean - 2 * sd, ymax = mean + 2 * sd), 
    width = 0.2, position = position_dodge(width = 0.2)
  ) + 
  facet_wrap(~ metric, scales = "free_y") + 
  labs(x = NULL, y = "CV-averaged performance") + 
  ylim(0, NA)
```

```{r}
extract_cv_tidy(s2_pol_cov, s2_pol_cov_nopop) %>% 
  select(model, term, mean = estimate, sd = std.error) %>% 
  mutate(
    model = if_else(model == "s2_pol_cov", "With pop.", "Without pop.")
  ) %>% 
  ggplot(aes(term, mean, color = model)) + 
  geom_point(position = position_dodge(0.8)) + 
  geom_errorbar(
    aes(ymin = mean - 2 * sd, ymax = mean + 2 * sd), 
    position = position_dodge(0.8), width = 0.2
  ) + 
  coord_flip(ylim = c(-3.5, 3.5))
```

### Fit charts

```{r}
plot_models(s2_pol_cov_nopop$object, dot.size = 2)
```

---

## 8. Log Time


```{r}
s2_pol_log_time <-  cache_operation(
  here("data/ts_model_s2_pol_log_time.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_log + 
       #time_days_since_inf1 + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       # This is the new interaction
       policy_recoded:time_log + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

No clear harm to the model fit, but no real imprevent either.

```{r}
extract_cv_glance(s2_pol_cov1_it, s2_pol_log_time)
extract_cv_perf(s2_pol_cov1_it, s2_pol_log_time)

s2_pol_log_time %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_log_time$object, dot.size = 2)
```

```{r}
# CV fold 1 only
plot_model(s2_pol_cov1_it$object[[1]], type = "diag")
plot_model(s2_pol_cov1_it$object[[1]], type = "resid")
plot_model(s2_pol_cov1_it$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov1_it %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```



---

```{r, include=F, echo=F}
# Shutdown the multisession
plan(sequential)
```
