---
title:  "Regression Model Development"
author: "Tom Shafer"
date:   "2020-06-11, updated 2020-06-13"
output: html_document
---

```{r setup, include=FALSE}
r_root <- rprojroot::find_rstudio_root_file()

knitr::opts_knit$set(root.dir = file.path(r_root))
knitr::opts_chunk$set(warning = FALSE, message = FALSE, dpi = 100)
knitr::opts_chunk$set(fig.width = 8, fig.height = 8)

ggplot2::theme_set(ggplot2::theme_minimal())
```

```{r init}
options(stringsAsFactors = F)

suppressPackageStartupMessages({
  library(tidyverse)
  library(here)
  library(rsample)
  library(glmmTMB)
  library(sjPlot)
  library(furrr)
  library(broom.mixed)
  library(yardstick)
  library(glue)
})

plan(multiprocess)
```


# Overview

## Objectives 

- [x] Generate data sample
- [x] Do not use pop weighting
- [x] Do feature engineering
- [x] Do basic feature selection
- [x] V-fold CV for evaluation
- [x] Better standardization
- [x] Collapse ages
- [x] Select down mobility data
- [x] Bigger CV sample
- [x] Add econ data
- [x] Look at trajectories
- [ ] Add deltas
- [ ] Add restriction loosening
- [ ] Add day-of-week encoding
- [ ] Add time since first retriction

- [x] Choose features
- [ ] Do residual analysis
- [ ] Add fittable covariate lag factor
- [ ] Add median age variable instead of age bins? Or in addition to?
- [x] add policy as a random slope (didn't work)
- [x] Do we want to exclude initial zeros?

## Results

- Negative-binomial model
- No zero inflation for now, having excluded many zeros
- Interacting time with policy is important
- Unclear if we should include economic data, small effects and 
  potential for confounding
- Unclear if we should include mobility data, large effect and helps to fit 
  but seems to confound policy

We might fit two models, one with random slopes and one without.
We should also look at how the policy coefficients move around with 
cofactors, especially if the cofactors do not change OOS performance.

---

# Setup and helper functions

Set `FORCE_MODEL_RUN <- TRUE` to re-run all calculations, 
even if a cached version is available.

```{r}
RANDOM_SEED <- -461698
FORCE_MODEL_RUN <- FALSE
```

```{r}
# Run a glmmTMB model via 5-fold cross-validation
# Per fold, this returns:
#  - the model object
#  - a coefficients table
#  - model summary table
#  - training performance metrics
#  - testing performance metrics
#  - the held-out testing data (for, e.g., plotting)
run_model_vfold <- function(formula, data, ziformula = ~0, seed = NULL) {
  if (!is.null(seed))
    set.seed(seed)
  
  group_vfold_cv(data, group = county_fip, v = 5) %>% 
    future_pmap_dfr(~ {
      tr <- training(.x)
      te <- assessment(.x)
      id <- .y
      
      message("Running fold: ", id)
      
      model <- glmmTMB(
        formula, 
        data = tr,
        family = glmmTMB::nbinom2(), 
        ziformula = ziformula)
      
      pred_tr <- predict(model, tr, type = "conditional")
      pred_te <- predict(model, te, type = "conditional", allow.new.levels	= T)
      
      metrics_tr <- tribble(
        ~ metric, ~ value,
        "ccc",    ccc_vec(tr$target, pred_tr), 
        "huber",  huber_loss_vec(tr$target, pred_tr), 
        "mae",    mae_vec(tr$target, pred_tr), 
        "rsq",    rsq_vec(tr$target, pred_tr)
      )
      
      metrics_te <- tribble(
        ~ metric, ~ value,
        "ccc",    ccc_vec(te$target, pred_te), 
        "huber",  huber_loss_vec(tr$target, pred_tr), 
        "mae",    mae_vec(te$target, pred_te), 
        "rsq",    rsq_vec(te$target, pred_te)
      )
  
      tibble(
        id = id,
        object = list(model),
        tidy = list(suppressMessages(broom.mixed:::tidy.glmmTMB(model))),
        glance = list(suppressMessages(broom.mixed:::glance.glmmTMB(model))),
        train = list(metrics_tr),
        test = list(metrics_te),
        test_data = list(te)
      )
  })
}
```

```{r}
# Extract model performance (train and test) from table(s) of CV results
# Aggregate if necessary
extract_cv_perf <- function(...) {
  input_names <- map_chr(rlang::exprs(...), as.character)
  inputs <- list(...)
  
  map2_dfr(inputs, input_names, ~ {
    .df <- .x
    .name <- .y
    out <- imap_dfr(set_names(c("train", "test")), ~ {
      .df %>%
        select(id, all_of(.x)) %>%
        unnest(all_of(.x)) %>%
        mutate(partition = .y, .before = everything())
      }) %>% 
      group_by(partition, metric) %>%
      summarize(mean = mean(value), sd = sd(value), .groups = "drop") %>%
      pivot_wider(
        id_cols = "metric",
        names_from = "partition",
        values_from = c("mean", "sd")
      ) %>%
      relocate(ends_with("train"), .after = "metric")
    if (.name != ".") out <- mutate(out, model = .name, .after = "metric")
    }) %>% 
    arrange(metric)
}

# Extract model summary data from table(s) of CV results, aggregating if necessary
extract_cv_glance <- function(...) {
  input_names <- map_chr(rlang::exprs(...), as.character)
  inputs <- list(...)
  map2_dfr(inputs, input_names, ~ {
    out <- .x %>% 
      select(id, glance) %>% 
      unnest(glance) %>% 
      pivot_longer(-id, names_to = "metric") %>% 
      group_by(metric) %>% 
      summarize(mean = mean(value), sd = sd(value), .groups = "drop")
    if (.y != ".") out <- mutate(out, model = .y, .after = "metric")
    out
    }) %>% 
    arrange(metric)
}

# Extract model coefs data from table(s) of CV results, aggregating if necessary
extract_cv_tidy <- function(...) {
  input_names <- map_chr(rlang::exprs(...), as.character)
  inputs <- list(...)
  map2_dfr(inputs, input_names, ~ {
    out <- .x %>% 
      select(id, tidy) %>% 
      unnest(tidy) %>% 
      group_by(effect, component, group, term) %>% 
      summarize(
        estimate = mean(estimate),
        std.error = sqrt(sum(std.error**2)),
        .groups = "drop"
      )
    if (.y != ".") out <- mutate(out, model = .y, .before = "estimate")
    out
    }) %>% 
    arrange(estimate)
}

# Extract random county-level predictions from a CV fit object
extract_cv_trajectories <- function(data, .per_fold = 1L, seed = NULL) {
  if (!is.null(seed))
    set.seed(seed)
  future_pmap_dfr(data, ~ {
    model <- ..2
    data  <- ..7
    
    # Sample random counties, then predict with the model
    data %>% 
      distinct(county_fip) %>% 
      sample_n(.per_fold) %>% 
      semi_join(data, ., by = "county_fip") %>%
      mutate(
        yhat = predict(model, ., allow.new.levels = T, type = "response")
      )
  })
}
```

```{r}
# Run an operation and save to disk
# Load from disk instead of re-execute if the file exists
cache_operation <- function(path, ...) {
  if (!file.exists(path) | FORCE_MODEL_RUN) {
    cat("Operation not cached; executing now\n")
    saveRDS(..., path)
  } else {
    cat("Loading operation from cache:\n")
    cat(glue("{path}\n"))
  }
  return(readRDS(path))
}
```

```{r}
# Show a model fit overlaid with policy windows
plot_w_policy <- function(data) {
  boxes <- data %>% 
    group_by(state, county, policy_recoded) %>% 
    summarize(start = min(date), end = max(date), .groups = "drop")
  
  data %>% 
    select(date, state, county, target, policy_recoded, yhat) %>% 
    pivot_longer(c(target, yhat)) %>% 
    ggplot() + 
    geom_rect(
      aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf, fill = policy_recoded), 
      data = boxes
    ) + 
    geom_line(aes(date, value, alpha = name, size = name)) +
    facet_wrap(~ state + county, scales = "free") + 
    scale_size_manual(values = c(0.5, 0.8)) + 
    scale_alpha_manual(values = c(0.6, 1)) + 
    scale_fill_viridis_d(alpha = 0.3)
}
```

---

# Data preparation

```{r load_data}
abt_v1 <- vroom::vroom(here("data/abt_prepped.csv")) %>% 
  rename_with(~ str_replace_all(., " ", "."))
```

## Feature engineering

### Days since first infection

```{r}
abt_v2 <- abt_v1 %>% 
  group_by(state_code, county_fip) %>% 
  arrange(state_code, county_fip, date) %>% 
  mutate(
    time_days_since_inf1 = suppressWarnings(as.integer(date - min(date[confirmed > 0])))
  ) %>% 
  ungroup() %>% 
  mutate(time_days_since_inf1 = if_else(
    is.na(time_days_since_inf1) | time_days_since_inf1 < 0, 
    -1L, 
    time_days_since_inf1
  ))
```

### Median income

Units of $10K appear meaningful, but this is easy to change.

```{r}
summary(abt_v2$acs_median_hh_inc_total)

abt_v2 <- abt_v2 %>% 
  mutate(
    acs_median_hh_inc_10k = acs_median_hh_inc_total / 10000, 
    .after = acs_median_hh_inc_total
  ) %>% 
  select(-acs_median_hh_inc_total)

summary(abt_v2$acs_median_hh_inc_10k)
```

### Population

We leave population alone for now, but a log transform is certainly possible.

```{r}
summary(abt_v2$acs_pop_total)
```

### Prior day's target

If we want to model day-over-day growth.

```{r}
dim(abt_v2)

abt_v2 <- abt_v2 %>% 
  group_by(state_code, county_fip) %>% 
  arrange(state_code, county_fip, date) %>% 
  mutate(target_lag1 = target - lag(target, 1), .after = target) %>% 
  ungroup() %>% 
  filter(!is.na(target_lag1))

dim(abt_v2)
```

---

## Data reduction for modeling

### Subset features

Subset to specific features:

```{r}
# Named vector renames
keep_columns <- c(
  "date", 
  "state_code", "county_fip", "state", "county", 
  "target", 
  "policy_recoded" = "policy",
  "time_dow", "time_wk_yr",
  "tmpf_mean", "relh_mean", 
  "pop_density", 
  "acs_pop_total",
  "acs_age_le_24", "acs_age_25_34", "acs_age_35_44", "acs_age_45_54", 
  "acs_age_55_64", "acs_age_65_74", "acs_age_75_84", "acs_age_85_ge", 
  "acs_race_minority", 
  "acs_gender_female",
  "acs_median_hh_inc_10k", 
  "cov_pos_tests", "cov_total_tests",
  "mobility_retail_and_recreation" = "retail_and_recreation", 
  "mobility_grocery_and_pharmacy" = "grocery_and_pharmacy", 
  "mobility_parks" = "parks", 
  "mobility_transit_stations" = "transit_stations", 
  "mobility_workplaces" = "workplaces", 
  "mobility_residential" = "residential",
  "time_days_since_inf1",
  "labor_force", "unemployed"
)

# Strings to factors in certain cases
abt_sub <- abt_v2 %>% 
  select(all_of(keep_columns)) %>% 
  mutate(across(c(where(is.character), -c(date:county)), factor))

dim(abt_sub)

abt_sub %>% 
  group_by(county_fip) %>% 
  summarize(nrow = n(), .groups = "drop") %>% 
  summarize(across(nrow, .fns = list(mean = mean, sd = sd)))

colSums(is.na(abt_sub))
```

### Subset rows 

**Important:** We are interested in policy impact on the changing COVID
landscape. So let's not model pre-testing, pre-policy times. Focus on times
_since_ positive cases.

```{r}
abt_sub <- abt_sub %>% filter(time_days_since_inf1 > -1)

# Cuts our rows substantially
dim(abt_sub)

abt_sub %>% 
  group_by(county_fip) %>% 
  summarize(nrow = n(), .groups = "drop") %>% 
  summarize(across(nrow, .fns = list(mean = mean, sd = sd)))
```

Still plenty of zeroes:

```{r}
abt_sub %>% 
  ggplot(aes(target)) + 
  geom_histogram(bins = 50) + 
  scale_y_log10()
```

---

## Feature standardization

 - Fractions -> percentages
 - Other continuous features -> standardized

```{r}
std_vars <- c(
  "tmpf_mean", "relh_mean", 
  "pop_density", 
  "acs_pop_total", "acs_median_hh_inc_10k", 
  "cov_pos_tests", "cov_total_tests"
)

frac_vars <- c(
  "acs_age_le_24", "acs_age_25_34", "acs_age_35_44", 
  "acs_age_45_54", "acs_age_55_64", "acs_age_65_74", 
  "acs_age_75_84", "acs_age_85_ge", "acs_race_minority", 
  "acs_gender_female",
  "labor_force", "unemployed"
)

std_table <- abt_sub %>% 
  select(all_of(std_vars)) %>% 
  map_dfr(~ tibble(mean = mean(.x), sd = sd(.x)), .id = "feature")
```

```{r}
# Apply the normalization
abt_sub_std <- abt_sub %>% 
  mutate(across(
    all_of(std_table$feature), ~ 
      (. - std_table[std_table$feature == cur_column(), ]$mean) /
      std_table[std_table$feature == cur_column(), ]$sd
  ))

# NB: models fit better as fractions
# abt_sub_std <- abt_sub_std %>% 
#   mutate(across(all_of(frac_vars), ~ 100 * .))
```

---

# Feature testing

Test features using the development subset.

## Boruta

Run Boruta against a large random sample of 20,000 rows.
We sample entire per-county trajectories ratehr than arbitrary random rows.
Boruta runs permutation tests against the input features using Random 
Forests to identify all _relevant_ features.

```{r}
save_path <- here("data/ts_boruta_sample.rds")

if (!file.exists(save_path) | FORCE_MODEL_RUN) {
  cat("Running Boruta\n")
  
  set.seed(RANDOM_SEED)
  bb <- abt_sub_std %>% 
    distinct(county_fip) %>% 
    sample_n(275) %>% 
    semi_join(abt_sub_std, ., by = "county_fip") %>% 
    select(-c(date:county)) %>% 
    Boruta::Boruta(target ~ ., data = ., maxRuns = 20, doTrace = 2)
  
  saveRDS(bb, save_path)
}

bb <- readRDS(save_path)
```

Boruta results:

 - `time_dow` is rejected
 - Feature importance looks different now that we start on infection "day zero"

```{r}
# Make a nicer Boruta importance history plot that lists all column names
bb$ImpHistory %>% 
  as_tibble(rownames = "iteration") %>% 
  pivot_longer(-iteration, names_to = "feature", values_to = "importance") %>% 
  filter(importance > -Inf) %>% 
  left_join(enframe(bb$finalDecision, "feature", "decision"), by = "feature") %>% 
  mutate(feature = fct_rev(fct_reorder(factor(feature), importance, median))) %>% 
  ggplot(aes(feature, importance, fill = decision)) + 
  geom_boxplot() + 
  coord_flip() + 
  scale_fill_discrete(na.translate = F)
``` 

---

## Correlations

 - Days since infection tracks week of the year, as you'd expect
   - Outcome: Do not use week of year
 - Age bins are quite correlated
   - Collapse older age bins together
   - Leave oldest bin separated (cf. nursing home outbreaks)
   - Drop ages < 24 from analysis to prevent model fit issues
 - Mobility is self-correlated, but at a lesser strength.
   - Cf. Mike and consider two elements: workplace and retail

```{r, fig.width=8, fig.height=8}
correlations <- abt_sub_std %>% 
  select(-c(date:county)) %>% 
  select(where(is.numeric)) %>% 
  cor()

correlations %>% 
  as_tibble(rownames = "feature1") %>% 
  pivot_longer(-feature1, names_to = "feature2", values_to = "correlation") %>% 
  # filter(feature1 == "acs_gender_female") %>% 
  filter(abs(correlation) > 0.6) %>% 
  filter(feature1 < feature2) %>% 
  arrange(-abs(correlation)) %>% 
  print(n = Inf)

corrplot::corrplot(
  correlations, 
  method = "color", 
  order = "hclust", 
  tl.col = "black", 
  tl.cex = 0.8
)
```

### Treat correlated features

#### COVID tests

Simple percentage normalization takes care of the correlation:

```{r}
abt_sub_std %>% 
  mutate(cov_pos_tests = 100 * cov_pos_tests / cov_total_tests) %>% 
  with(cor(cov_pos_tests, cov_total_tests))
```

Using the Boruta results, we include the most "important" features and then
look at the impact of changing our COVID testing parameterization.

```{r}
set.seed(RANDOM_SEED)

m1_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests + cov_total_tests + 
      (1|state_code/county_fip), 
    data = .
  )

set.seed(RANDOM_SEED)

m2_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  mutate(cov_pos_tests = cov_pos_tests / cov_total_tests) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests + cov_total_tests + 
      (1|state_code/county_fip), 
    data = .
  )

# No major difference, so OK to change.
bind_rows(
  glance(m1_) %>% mutate(model = "original", .before = everything()),
  glance(m2_) %>% mutate(model = "new", .before = everything())
)
```

Implement the change:

```{r}
abt_sub_std <- abt_sub_std %>% 
  mutate(cov_pos_tests_frac = cov_pos_tests / cov_total_tests)

abt_sub <- abt_sub %>% 
  mutate(cov_pos_tests_frac = if_else(
    cov_total_tests == 0, 
    0, 
    cov_pos_tests / cov_total_tests)
  )
```

#### Age binning

Based on the correlation analysis we should reduce the number of age bins.
Then carry out a similar test as above.

```{r}
# This deals with r > 0.7 (dropping ages le 24, which will roll into the intercept)
abt_sub_std %>% 
  mutate(
    acs_age_25_54 = acs_age_25_34 + acs_age_35_44 + acs_age_45_54,
    acs_age_55_84 = acs_age_55_64 + acs_age_65_74 + acs_age_75_84,
    .keep = "unused"
  ) %>%
  select(starts_with("acs_age")) %>% 
  cor()
```

Test the modeling impact:

```{r}
set.seed(RANDOM_SEED)

m1_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + 
      cov_total_tests + 
      acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + 
      acs_age_55_64 + acs_age_65_74 + acs_age_75_84 + acs_age_85_ge +
      (1 | state_code/county_fip), 
    data = .
  )

set.seed(RANDOM_SEED)

m2_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  mutate(
    acs_age_25_54 = acs_age_25_34 + acs_age_35_44 + acs_age_45_54,
    acs_age_55_84 = acs_age_55_64 + acs_age_65_74 + acs_age_75_84,
    .keep = "unused"
  ) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + cov_total_tests + 
      acs_age_25_54 + acs_age_55_84 + acs_age_85_ge +
      (1 | state_code/county_fip), 
    data = .
  )

# No major difference, so OK to change.
bind_rows(
  glance(m1_) %>% mutate(model = "original", .before = everything()),
  glance(m2_) %>% mutate(model = "new", .before = everything())
)
```

Implement the change:

```{r}
abt_sub_std <- abt_sub_std %>% 
  mutate(
    acs_age_25_54 = acs_age_25_34 + acs_age_35_44 + acs_age_45_54,
    acs_age_55_84 = acs_age_55_64 + acs_age_65_74 + acs_age_75_84
  )

abt_sub <- abt_sub %>% 
  mutate(
    acs_age_25_54 = acs_age_25_34 + acs_age_35_44 + acs_age_45_54,
    acs_age_55_84 = acs_age_55_64 + acs_age_65_74 + acs_age_75_84
  )
```

#### Mobility subsets

Check the mobility correlations:

```{r}
# This agrees with Mike's notion that retail & rec and workplaces covers it
abt_sub_std %>% 
  select(starts_with("mobility")) %>% 
  cor() %>% 
  as_tibble(rownames = "item1") %>% 
  pivot_longer(-item1, "item2") %>% 
  filter(item1 < item2) %>% 
  arrange(-abs(value))
```

Test the effect of only including two features:

```{r}
set.seed(RANDOM_SEED)

m1_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + 
      cov_total_tests + 
      mobility_retail_and_recreation + mobility_grocery_and_pharmacy + 
      mobility_parks + mobility_transit_stations + 
      mobility_workplaces + mobility_residential + 
      (1 | state_code/county_fip), 
    data = .
  )

set.seed(RANDOM_SEED)

m2_ <- abt_sub_std %>% 
  sample_n(10000) %>% 
  glmmTMB(
    formula = target ~ 
      time_days_since_inf1 + 
      acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
      unemployed + 
      cov_pos_tests_frac + 
      cov_total_tests + 
      mobility_retail_and_recreation + mobility_workplaces + 
      (1 | state_code/county_fip), 
    data = .
  )

# No major difference, so OK to change.
bind_rows(
  glance(m1_) %>% mutate(model = "original", .before = everything()),
  glance(m2_) %>% mutate(model = "new", .before = everything())
)
```

(No change to implement.)

---

## Univariate target associations

For each feature in our data, how well does it help fits? 
How well does it fit held out data? 
What are its standalone parameter estimates?

Numerics:

```{r, fig.height=8, fig.width=10}
set.seed(RANDOM_SEED)
abt_sub_std %>% 
  sample_n(10000) %>% 
  select(-c(date:county), state_code) %>% 
  select(target, state_code, where(is.numeric)) %>% 
  mutate(target_scaled = target / acs_pop_total) %>% 
  pivot_longer(-c(target, target_scaled, state_code)) %>% 
  ggplot(aes(value, target, group = state_code)) + 
  geom_smooth(method = "glm", size = 0.5, alpha = 0.5) + 
  facet_wrap(~ name, scales = "free_x") + 
  theme(aspect.ratio = 9 / 16) + 
  labs(title = "Per-state glm")


set.seed(RANDOM_SEED)
abt_sub_std %>% 
  sample_n(10000) %>% 
  select(-c(date:county), state_code) %>% 
  select(target, state_code, where(is.numeric)) %>% 
  mutate(target_scaled = target / acs_pop_total) %>% 
  pivot_longer(-c(target, target_scaled, state_code)) %>% 
  ggplot(aes(value, target)) + 
  geom_smooth(size = 0.5, alpha = 0.5) + 
  facet_wrap(~ name, scales = "free_x") + 
  theme(aspect.ratio = 9 / 16) + 
  labs(title = "Total")
```

Factors:

```{r}
sample_abt %>% 
  select(-c(date:county)) %>% 
  select(target, where(is.factor)) %>% 
  pivot_longer(-target) %>% 
  ggplot(aes(value, target)) + 
  geom_boxplot(outlier.shape = NA) + 
  facet_wrap(~ name, scales = "free_x") + 
  ylim(0, 40)
```

We'll tackle interactions during modeling.

---

# Data samples for development

## Sample 1: 10 counties by 10 states

To keep development snappy, take 10 counties per state for 10 states. (Yes, this
is biased, but it allows for several kinds of useful tests.)

```{r}
set.seed(RANDOM_SEED)

sample_ids <- abt_sub_std %>% 
  group_by(state, state_code) %>% 
  summarize(n_counties = n_distinct(county_fip), .groups = "drop") %>% 
  filter(n_counties > 20) %>% 
  sample_n(10) %>% 
  left_join(abt_sub_std, by = c("state", "state_code")) %>% 
  distinct(state, state_code, county, county_fip) %>% 
  group_by(state_code) %>% 
  sample_n(10) %>% 
  ungroup()

sample_abt <- abt_sub_std %>% 
  semi_join(sample_ids, by = c("state", "state_code", "county", "county_fip"))

dim(sample_abt)
```

## Sample 2: 40 counties by 25 states

Re-standardize, etc.

 - <http://www.stat.columbia.edu/~gelman/research/published/standardizing7.pdf>
 - Statistical rethinking, ch 5
 
```{r}
set.seed(RANDOM_SEED)

sample2_ids <- abt_sub %>% 
  group_by(state, state_code) %>% 
  summarize(n_counties = n_distinct(county_fip), .groups = "drop") %>% 
  filter(n_counties > 40) %>% 
  sample_n(25) %>% 
  left_join(abt_sub_std, by = c("state", "state_code")) %>% 
  distinct(state, state_code, county, county_fip) %>% 
  group_by(state_code) %>% 
  sample_n(40) %>% 
  ungroup()

sample2_abt <- abt_sub %>% 
  semi_join(sample2_ids, by = c("state", "state_code", "county", "county_fip"))

dim(sample2_abt)
summary(sample2_abt)
```

Check distributions:

 - Fix pop. and pop. density skew with a log
 - Fix all ACS with skew using log
 - Fix COVID-19 testing using log(1+x)

```{r}
sample2_abt %>%
  mutate(across(c(pop_density, starts_with("acs")), log)) %>% 
  mutate(across(starts_with("cov"), log1p)) %>% 
  select(where(is.numeric), -county_fip) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(value)) + 
  geom_histogram(bins = 50) + 
  facet_wrap(~ name, scales = "free")
```
 
 Remove variables we plan not to use.
 The target is OK because we're modeling as a negative binomial.
 NB: We might be introducing a bit of bias by doing this scaling outside of CV.

```{r}
sample2_abt <- sample2_abt %>% 
  mutate(
    across(c(pop_density, starts_with("acs")), log),
    across(starts_with("cov"), log1p)
  ) %>% 
  select(-c(
    time_wk_yr, 
    acs_age_25_34:acs_age_75_84,
    mobility_grocery_and_pharmacy, mobility_transit_stations, mobility_residential
  )) %>% 
  # circle-encode day of week
  mutate(
    time_dow_x = cos(2 * pi * (as.integer(time_dow) - 1) / 7),
    time_dow_y = sin(2 * pi * (as.integer(time_dow) - 1) / 7),
    .keep = "unused",
    .after = "time_dow"
  ) %>% 
  # standardize
  mutate(across(time_dow_x:acs_age_55_84, ~ (. - mean(.)) / (2 * sd(.))))

dim(sample2_abt)
summary(sample2_abt)
```

```{r}
sample2_abt %>% 
  select(where(is.numeric), -county_fip) %>% 
  pivot_longer(everything()) %>% 
  ggplot(aes(value)) + 
  geom_histogram(bins = 50) + 
  facet_wrap(~ name, scales = "free")
```

---

# Model building: Sample 1

We initially applied a zero-inflated negative-binomial model, but after 
removing the initial zeros it seems not to be needed.

Here we use out small CV sample to add features and test CV performance.

---

## Initial random intercepts baseline model

```{r}
save_path <- here("data/ts_model_baseline.rds")

if (!file.exists(save_path) | FORCE_MODEL_RUN) {
  cat("Running model\n")
  
  baseline <- run_model_vfold(
    formula = target ~ 1 + (1 | state_code/county_fip),
    data = sample_abt, 
    ziformula = ~ 1 + (1 | state_code/county_fip)
  )
  saveRDS(baseline, save_path)
}

baseline <- readRDS(save_path)
```

```{r}
baseline %>% extract_cv_glance()
baseline %>% extract_cv_perf()
```

### Without zero inflation

```{r}
save_path <- here("data/ts_model_baseline_nozi.rds")

if (!file.exists(save_path) | FORCE_MODEL_RUN) {
  cat("Running model\n")
  
  baseline_nozi <- run_model_vfold(
    formula = target ~ 1 + (1 | state_code/county_fip),
    data = sample_abt
  )
  saveRDS(baseline_nozi, save_path)
}

baseline_nozi <- readRDS(save_path)
```

Little difference in performance.

```{r}
baseline_nozi %>% extract_cv_glance()
baseline_nozi %>% extract_cv_perf()
```

### With time

```{r}
save_path <- here("data/ts_model_baseline_time.rds")

if (!file.exists(save_path) | FORCE_MODEL_RUN) {
  cat("Running model\n")
  
  baseline_time <- run_model_vfold(
    formula = target ~ 1 + time_days_since_inf1 + (1 | state_code/county_fip),
    data = sample_abt
  )
  saveRDS(baseline_time, save_path)
}

baseline_time <- readRDS(save_path)
```

```{r}
baseline_time %>% extract_cv_glance()
baseline_time %>% extract_cv_perf()
```

---

## Larger models

Build a sequence of larger models, measuring fit and OOS performance.
This will give a rough idea of allowable model complexity, which we can
then fine tune.
NB: Each model is saved for later reuse.

```{r}
larger_model_formulae <- list(
  "larger_dem_pop_test" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_polrs" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    (1 + policy_recoded | state_code) + 
    (1 | state_code:county_fip),
  
  "larger_dem_pop_test_mob" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip_id" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    policy_recoded:mobility_workplaces + 
    policy_recoded:mobility_grocery_and_pharmacy + 
    policy_recoded:mobility_transit_stations + 
    policy_recoded:mobility_residential + 
    acs_pop_total:acs_median_hh_inc_10k + 
    acs_race_minority:acs_median_hh_inc_10k + 
    acs_pop_total:acs_race_minority + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip_id_im" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    acs_pop_total:acs_median_hh_inc_10k + 
    acs_race_minority:acs_median_hh_inc_10k + 
    acs_pop_total:acs_race_minority + 
    policy_recoded:mobility_workplaces + 
    policy_recoded:mobility_grocery_and_pharmacy + 
    policy_recoded:mobility_transit_stations + 
    policy_recoded:mobility_residential + 
    (1 | state_code/county_fip),
  
  "larger_dem_pop_test_mob_ip_id_ia" = target ~ 1 + 
    time_days_since_inf1 + 
    # Demographics
    acs_pop_total + acs_median_hh_inc_10k + acs_race_minority + 
    acs_age_25_34 + acs_age_35_44 + acs_age_45_54 + acs_age_55_64 + 
    acs_age_65_74 + acs_age_75_84 + acs_age_85_ge + 
    # Policy
    policy_recoded + 
    # Testing
    cov_pos_tests + cov_total_tests + 
    # Policy effectiveness
    mobility_retail_and_recreation + 
    mobility_grocery_and_pharmacy + 
    mobility_parks + 
    mobility_transit_stations + 
    mobility_workplaces + 
    mobility_residential +
    # Interactions
    time_days_since_inf1:policy_recoded + 
    acs_pop_total:acs_median_hh_inc_10k + 
    acs_race_minority:acs_median_hh_inc_10k + 
    acs_pop_total:acs_race_minority + 
    policy_recoded:(acs_age_65_74 + acs_age_75_84 + acs_age_85_ge) + 
    acs_median_hh_inc_10k:(acs_age_65_74 + acs_age_75_84 + acs_age_85_ge) + 
    acs_race_minority: (acs_age_65_74 + acs_age_75_84 + acs_age_85_ge) +
    (1 | state_code/county_fip)
)
```

```{r}
# These run serially, but the CV is parallelized
iwalk(larger_model_formulae, ~ {
  save_path <- here(glue("data/ts_model_{.y}.rds"))

  if (!file.exists(save_path) | FORCE_MODEL_RUN) {
    cat(glue("Running model {.y}"), "\n\n")
    
    model <- run_model_vfold(
      formula = .x,
      data = sample_abt
    )
    saveRDS(model, save_path)
  }
})
```

```{r}
larger_models <- larger_model_formulae %>% 
  imap(~ readRDS(here(glue("data/ts_model_{.y}.rds"))))
```

### Model performance measures

### AIC, BIC, etc

Hard to say anything based on BIC. These models are difficult.

```{r}
larger_models %>% 
  imap_dfr(~ {
    .x %>% 
      select(glance) %>% 
      unnest(glance)
  }, .id = "model") %>% 
  select(-sigma) %>% 
  group_by(model) %>% 
  summarize(across(.fns = list(mean = mean, sd = sd)), .groups = "drop")
```

### Train vs test performance

Again, hard to say these (very large) models are overfit. 
Very larger error bars.

```{r}
larger_models %>% 
  map_dfr(extract_cv_perf, .id = "model") %>% 
  pivot_longer(
    mean_train:sd_test, 
    names_to = c("measure", "partition"), 
    names_sep = "_"
  ) %>% 
  pivot_wider(names_from = "measure") %>% 
  ggplot(aes(model, mean, color = partition)) + 
  geom_point(alpha = 0.5) + 
  geom_errorbar(
    aes(ymin = mean - sd, ymax = mean + sd), 
    size = 0.5, width = 0, alpha = 0.5
  ) + 
  facet_wrap(~ metric, scales = "free_x") + 
  coord_flip()
```

### Model visualization

```{r, echo=F}
# Visualize the fixed effects for 1 CV fold
iwalk(larger_models, ~ print(plot_model(.x$object[[1]], title = .y, type = "est")))
```

### Model coefficients aggregation

```{r}
# This is simple error propagation assuming independent obvs as a way to combine fits
s1_coef_agg <- larger_models %>% 
  map_dfr(~ {
    select(.x, tidy) %>% 
      unnest(tidy) %>% 
      group_by(effect, component, group, term) %>% 
      summarize(
        estimate = mean(estimate), 
        std.error = sqrt(sum(std.error**2)), 
        .groups = "drop"
      )
  }, .id = "model")


s1_coef_agg %>% 
  ggplot(aes(model, estimate)) + 
  geom_hline(yintercept = 0) + 
  geom_point() + 
  geom_errorbar(
    aes(ymin = estimate - 2 * std.error, ymax = estimate + 2 * std.error)
  ) + 
  facet_wrap(~ term, scales = "free_y")
```

---

# Model building: Sample 2

Similar tests, but with a larger sample.

We also start from policy and add features that (1) help prediction and 
(2) might help with policy inference.

---

## 0. Policy-only baseline

This is the baseline; it won't be good.

```{r}
s2_pol_bl <- cache_operation(
  here("data/ts_model_s2_pol_bl.rds"), {
    run_model_vfold(
     formula = target ~ 1 + policy_recoded + (1 | state_code/county_fip),
     data = sample2_abt, 
     seed = RANDOM_SEED
    )
})
```

### Stats tables

```{r}
s2_pol_bl %>% extract_cv_glance()
s2_pol_bl %>% extract_cv_perf()
s2_pol_bl %>% extract_cv_tidy()
```

### Fit charts

```{r}
plot_models(s2_pol_bl$object)
plot_model(s2_pol_bl$object[[1]], type = "resid")
plot_model(s2_pol_bl$object[[1]], type = "diag")
```

```{r}
plot_model(s2_pol_bl$object[[1]], type = "re")
```

### Trajectory plots

Sample a few counties, two from each fold, and plot predictions.
Note that the fits are OK, but the directionality makes no sense because
we are missing many covariates (the above residual plot makes sens, though).

```{r}
s2_pol_bl %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 1. Introduce key covariates

New covariates:

 - Time since first reported infection
 - Day of the week
 - Population and population density
 - Demographics
 - COVID-19 testing

```{r}
FORCE_MODEL_RUN <- 0
s2_pol_cov <- cache_operation(
  here("data/ts_model_s2_pol_kcov.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       time_dow_x + time_dow_y + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

This helps tremendously, with $R^2 = 0.65(15)$ on held out data.

```{r}
extract_cv_glance(s2_pol_bl, s2_pol_cov)
extract_cv_perf(s2_pol_bl, s2_pol_cov)

s2_pol_cov %>% extract_cv_tidy()
```

### Fit charts

 - Results are consistent
 - Right now, all policies are mainly correlated with rising cases, which
   really suggests we haven't captured the effects yet
 - Day of week doesn't help

```{r}
plot_models(s2_pol_cov$object, dot.size = 2)
plot_model(s2_pol_cov$object[[1]], type = "resid")
plot_model(s2_pol_cov$object[[1]], type = "diag")
```

```{r}
plot_model(s2_pol_cov$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov %>% 
  cv_extract_preds(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 2. Policy with economics

**NB:** This was without pop_density.

```{r}
s2_pol_cov1_econ <- here("data/ts_model_s2_pol_cov_econ.rds") %>%
  cache_operation({
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       labor_force + unemployed + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

```{r}
# Compare to models without time interactions, to be on equal footing
extract_cv_glance(s2_pol_cov1_econ, s2_pol_cov)
extract_cv_perf(s2_pol_cov1_econ, s2_pol_cov)

# Very small effects
s2_pol_cov1_econ %>% 
  extract_cv_tidy()
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_econ$object, dot.size = 2)

plot_model(s2_pol_cov1_econ$object[[1]], type = "diag")
plot_model(s2_pol_cov1_econ$object[[1]], type = "resid")
```

```{r}
plot_model(s2_pol_cov1_econ$object[[1]], type = "re")
```

```{r}
fixef(s2_pol_cov1_econ$object[[1]]) %>% as_vector() %>% enframe()
ranef(s2_pol_cov1_econ$object[[1]]) %>% as_tibble()
```

### Trajectory plots

```{r}
s2_pol_cov1_econ %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 3. Policy with mobility

```{r}
s2_pol_cov1_econ_mob <- here("data/ts_model_s2_pol_cov_econ_mob.rds") %>%
  cache_operation({
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       labor_force + unemployed + 
       mobility_retail_and_recreation + mobility_workplaces + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

```{r}
# Compare to models without time interactions, to be on equal footing
extract_cv_glance(s2_pol_cov1_econ_mob, s2_pol_cov)
extract_cv_perf(s2_pol_cov1_econ_mob, s2_pol_cov)

# Very small effects
s2_pol_cov1_econ_mob %>% extract_cv_tidy()
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_econ_mob$object, dot.size = 2)

# Only look at 1st CV fold
plot_model(s2_pol_cov1_econ_mob$object[[1]], type = "diag")
plot_model(s2_pol_cov1_econ_mob$object[[1]], type = "resid")
```

```{r}
# Only look at 1st CV fold
plot_model(s2_pol_cov1_econ_mob$object[[1]], type = "re")
```

```{r}
# Only look at 1st CV fold
fixef(s2_pol_cov1_econ_mob$object[[1]]) %>% as_vector() %>% enframe()
ranef(s2_pol_cov1_econ_mob$object[[1]]) %>% as_tibble()
```

### Trajectory plots

```{r}
s2_pol_cov1_econ_mob %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 4. Policy-time interactions

Allow policy to interact with time through a term

$$
\frac{\partial^2 y}{\partial t \partial p} = 
  \frac{\partial}{\partial p}\frac{\partial y}{\partial t}
$$
that attempts to capture how the rate of progression changes with policy.

**NB:* This was run before pop. density or day of week were included.

```{r}
s2_pol_cov1_it <-  cache_operation(
  here("data/ts_model_s2_pol_kcov_it_200613.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       # This is the new interaction
       policy_recoded:time_days_since_inf1 + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

No clear harm to the model fit, but no real imprevent either.

```{r}
extract_cv_glance(s2_pol_cov, s2_pol_cov1_it)
extract_cv_perf(s2_pol_cov, s2_pol_cov1_it)

s2_pol_cov1_it %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_it$object, dot.size = 2)
```

```{r}
# CV fold 1 only
plot_model(s2_pol_cov1_it$object[[1]], type = "diag")
plot_model(s2_pol_cov1_it$object[[1]], type = "resid")
plot_model(s2_pol_cov1_it$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov1_it %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 5. More time interactions

We ask whether race, income, or pop. density affect the trajectory.

```{r}
s2_pol_cov1_it2 <- cache_operation(here("data/ts_model_s2_pol_simpler_it.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       policy_recoded:time_days_since_inf1 + 
       # These are the new interactions
       acs_median_hh_inc_10k:time_days_since_inf1 + 
       acs_race_minority:time_days_since_inf1 + 
       pop_density:time_days_since_inf1 + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

Out-of-sample we are marginally, but nowhere near significantly, better.

```{r}
extract_cv_glance(s2_pol_cov1_it2, s2_pol_cov1_it)
extract_cv_perf(s2_pol_cov1_it2, s2_pol_cov1_it)

s2_pol_cov1_it2 %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_cov1_it2$object, dot.size = 2)

plot_model(s2_pol_cov1_it2$object[[1]], type = "diag")
plot_model(s2_pol_cov1_it2$object[[1]], type = "resid")
```

```{r}
plot_model(s2_pol_cov1_it2$object[[1]], type = "re")
```

### Trajectory plots

```{r}
s2_pol_cov1_it2 %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 6. Random slopes with time

**NB:** A model with random slope interactions didn't converge.

```{r}
s2_pol_simpler_rt <- here("data/ts_model_s2_pol_simpler_rt_200613.rds") %>%
  cache_operation({
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       acs_pop_total + 
       acs_race_minority + 
       acs_gender_female +
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge +
       cov_total_tests + cov_pos_tests_frac + 
       policy_recoded:time_days_since_inf1 + 
       (1 + time_days_since_inf1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

Massive improvement in model fit metrics, and reasonable improvement
in out-of-sample metrics,.

```{r}
extract_cv_glance(s2_pol_simpler_rt, s2_pol_cov1_it)
extract_cv_perf(s2_pol_simpler_rt, s2_pol_cov1_it)

s2_pol_simpler_rt %>% 
  extract_cv_tidy() %>% 
  print(n = Inf)
```

### Fit charts

```{r}
plot_models(s2_pol_simpler_rt$object, dot.size = 2)
```

```{r}
# Only looking at CV fold 1
plot_model(s2_pol_simpler_rt$object[[1]], type = "diag")
plot_model(s2_pol_simpler_rt$object[[1]], type = "resid")
plot_model(s2_pol_simpler_rt$object[[1]], type = "re")
```

```{r}
fixef(s2_pol_simpler_rt$object[[1]]) %>% as_vector() %>% enframe()
ranef(s2_pol_simpler_rt$object[[1]]) %>% as_tibble()
```

### Trajectory plots

```{r}
s2_pol_simpler_rt %>% 
  extract_cv_trajectories(.per_fold = 2, seed = RANDOM_SEED) %>% 
  plot_w_policy()
```

---

## 7. For Carlos: No population

```{r}
s2_pol_cov_nopop <- cache_operation(
  here("data/ts_model_s2_pol_kcov_nopop.rds"), {
    run_model_vfold(
     formula = target ~ 1 + 
       policy_recoded + 
       time_days_since_inf1 + 
       time_dow_x + time_dow_y + 
       pop_density + 
       acs_race_minority + 
       acs_gender_female + 
       acs_median_hh_inc_10k + 
       acs_age_le_24 + acs_age_25_54 + acs_age_55_84 + acs_age_85_ge + 
       cov_total_tests + cov_pos_tests_frac + 
       (1 | state_code/county_fip),
     data = sample2_abt
    )
  })
```

### Stats tables

- No big changes in fit stats, except that the across-fold SD drops way down.
- The nopop model has worse out-of-sample accuracy b/c we've elimintated
  a shared effect that goes into the model.

```{r}
# Compare to sibling model
extract_cv_glance(s2_pol_cov, s2_pol_cov_nopop)
extract_cv_perf(s2_pol_cov, s2_pol_cov_nopop)
```

```{r}
# Comparison plots
extract_cv_perf(s2_pol_cov, s2_pol_cov_nopop) %>% 
  pivot_longer(mean_train:sd_test, names_to = c("measure", "part"), names_sep = "_") %>%
  pivot_wider(names_from = "measure") %>% 
  mutate(
    part = factor(
      if_else(part == "train", "Train", "Test"), 
      levels = c("Train", "Test")
    ),
    metric = case_when(
      metric %in% c("ccc", "mae") ~ str_to_upper(metric),
      metric == "rsq" ~ "R-squared",
      TRUE ~ str_to_title(metric)
    ),
    model = if_else(model == "s2_pol_cov", "With pop.", "Without pop.")
  ) %>% 
  ggplot(aes(part, mean, color = model)) + 
  geom_point(position = position_dodge(width = 0.2)) + 
  geom_errorbar(
    aes(ymin = mean - 2 * sd, ymax = mean + 2 * sd), 
    width = 0.2, position = position_dodge(width = 0.2)
  ) + 
  facet_wrap(~ metric, scales = "free_y") + 
  labs(x = NULL, y = "CV-averaged performance") + 
  ylim(0, NA)
```

```{r}
extract_cv_tidy(s2_pol_cov, s2_pol_cov_nopop) %>% 
  select(model, term, mean = estimate, sd = std.error) %>% 
  mutate(
    model = if_else(model == "s2_pol_cov", "With pop.", "Without pop.")
  ) %>% 
  ggplot(aes(term, mean, color = model)) + 
  geom_point(position = position_dodge(0.8)) + 
  geom_errorbar(
    aes(ymin = mean - 2 * sd, ymax = mean + 2 * sd), 
    position = position_dodge(0.8), width = 0.2
  ) + 
  coord_flip(ylim = c(-3.5, 3.5))
```

### Fit charts

```{r}
plot_models(s2_pol_cov_nopop$object, dot.size = 2)
```

---

```{r, include=F, echo=F}
# Shutdown the multisession
plan(sequential)
```
