---
title:  "SIR Regression Model"
author: "Tom Shafer"
date:   "2020-06-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
options(stringsAsFactors = FALSE)

library(magrittr)
library(tidyverse)
library(here)
library(brms)
library(tidybayes)
library(furrr)
library(lme4)
```


# Overview

## Objective

Fit SIR models through time, preferably using BRMS, to estimate the effects of various interventions.

## Theory

Converting the equation for $\dot I(t)$ to a difference equation gives
$$
I(T+1) = I(T) \cdot \left[ (1 - \gamma) + \beta S(T) / N \right],
$$
with $N$ the population size. This makes a number of assumptions, including homogeneous mixing and that a county's population is fixed within the county. In practice this shouldn't matter because the _effect_ spreading community size for an individual is much smaller than their entire county.

## Results


# Data prep

## Loading and checking

Using the raw CDC data until the ABT is solidified:

```{r}
cdc_raw <- read_csv(here("data/CDC_full_data.csv"))
acs_pop_raw <- read_csv(here("data/acs_dem_pop.csv"))
```

NB: Two "counties" don't have ACS data, but one is a cruise ship and the other doesn't exist on Wikipedia.

```{r}
abt_raw <- acs_pop_raw %>% 
  mutate(county_fip = as.integer(str_c(state_fips, county_fips))) %>% 
  left_join(cdc_raw, ., by = "county_fip")

abt_raw %>% 
  filter(is.na(county_fips)) %>% 
  distinct(county_fip, .keep_all = T) %>% 
  select(county_fip:county)

# Remove these two "counties"
abt_raw <- abt_raw %>% filter(!is.na(state_fips))
```

No missing values:

```{r}
abt_raw %>% 
  summarize(across(.fn = ~ sum(is.na(.)))) %>% 
  gather(column, na_values) %>% 
  knitr::kable()
```


## Data reshaping

We need to put the data in SIR form.

 - *I(t)* can be calculated as a difference of `confirmed`
 - *S(t)* can be calculated directly from `confirmed` and the ACS population

### SIR data cleaning

Some $I(t)$ and $\mathbb{I}(T) \equiv \sum_{t=0}^T I(t)$ entries are negative, maybe because of corrections to the data. So we apply an approach that:

 1. Corrects $I(t) \to 0$ if negative
 2. Back-corrects $\mathbb{I}(t-1)$ and $I(t-1)$ to make things work out OK

```{r}
# Back-correct the confirmed infection counts to make changes non-negative.
# This function takes a vector, computes the difference between entries, 
# and fixed negative values.
correct_negative_it <- function(col) {
  new_col <- c(col)
  # Iterate backwards to index 2 (leave 1 out for caluclating difference)
  for (i in seq(length(new_col), 2, -1)) {
    it <- new_col[i] - new_col[i - 1]
    if (it >= 0) next
    # Make it go to zero by fixing the last record
    new_col[i - 1] <- new_col[i - 1] + it
  }
  new_col
}
```

```{r}
abt_sir_1 <- abt_raw %>% 
  group_by(county_fip) %>% 
  arrange(county_fip, date) %>% 
  mutate(
    confirmed_orig = confirmed, 
    confirmed = correct_negative_it(confirmed_orig)
  ) %>% 
  ungroup()
```

```{r, eval=F, include=F}
# Check
check_abt_1 <- abt_sir_1 %>% 
  group_by(county_fip) %>% 
  arrange(county_fip, date) %>% 
  transmute(
    date, 
    confirmed, 
    confirmed_orig,
    confirmed_lag = lag(confirmed_orig), 
    delta = confirmed_orig - confirmed_lag
  )

# This is the problem
check_abt_1 %>% 
  filter(delta < 0) %>% 
  arrange(delta)

check_abt_1 %>%
  filter(county_fip == 32003) %>%
  select(date, confirmed, confirmed_lag, delta) %>%
  mutate(bad = if_else(delta < 0, "***", "")) %>% 
  View()

abt_sir_1 <- abt_raw %>% 
  group_by(county_fip) %>% 
  arrange(county_fip, date) %>% 
  mutate(
    old_confirmed = confirmed,
    confirmed = correct_negative_it(old_confirmed)
  ) %>% 
  ungroup()
```

### SIR transformation




## Partitioning

No partitions, not inferring.


## Final form

Apply the SIR transformations.

Assumption: We only consider counties that have reported anything. Because
we want to track the progression, not whether it exists in a county or not.
And including many zeros seems bad for the model.

```{r}
abt_final <- abt_sir_1 %>% 
  group_by(county_fip) %>% 
  arrange(county_fip, date) %>% 
  transmute(
    state_code,
    date, 
    pop = acs_pop_total, 
    cuml_inf = confirmed,
    cuml_inf_norm = confirmed / pop,
    suscept = pop - confirmed, 
    suscept_norm = suscept / pop,
    daily_inf = confirmed - lag(confirmed), 
    daily_inf_p1 = lead(daily_inf)
  ) %>% 
  na.omit() %>% 
  ungroup()

# Remove counties with no records _and_ the weeks without reporting
# at the front of the curve.
abt_final <- abt_final %>% 
  group_by(county_fip) %>% 
  arrange(county_fip, date) %>% 
  group_modify(~ {
    .x$ok <- as.integer(any(.x$daily_inf > 0))
    .x$min_date <- min(.x$date[.x$daily_inf > 0])
    .x
  })

abt_final <- abt_final %>% 
  filter(ok == 1, date >= min_date) %>% 
  ungroup()

head(abt_final)
```

```{r}
cor(abt_final[,c("daily_inf", "suscept", "suscept_norm", "cuml_inf")])
```


# Modeling

## Check the data

### Option 1: Differencing

```{r}
abt_final %>%
  sample_n(1e4) %>% 
  ggplot(aes(daily_inf, daily_inf_p1)) + 
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10()
```

```{r}
abt_final %>%
  sample_n(1e4) %>% 
  ggplot(aes(cuml_inf, daily_inf_p1)) + 
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10()
```

```{r}
abt_final %>%
  sample_n(1e4) %>% 
  ggplot(aes(cuml_inf, daily_inf)) + 
  geom_point() + 
  scale_x_log10() + 
  scale_y_log10()
```

```{r}
abt_final %>% 
  filter(county_fip==37183) %>% 
  ggplot(aes(date)) + 
  geom_line(aes(y=daily_inf), color='red') + 
  geom_line(aes(y=cuml_inf), color='blue')
```




## Simple linear regression

Fit simple linear regressions at various levels to convince myself this is worth pursuing further.

```{r}
fit_lm <- function(data) {
  lm(daily_inf_p1 ~ daily_inf + daily_inf:suscept_norm, data = data)
}
```


```{r}
extract_lm <- function(tbl, model_col, which = c("summary", "coefs")) {
  which <- match.arg(which, several.ok = T)
  assertthat::are_equal(nrow(tbl), 1)
  
  # Get model summary and convert to "term/estimate" format
  ms_ <- tibble()
  if ("summary" %in% which) {
    ms_ <- tbl %>% 
      pull({{model_col}}) %>% 
      extract2(1) %>% 
      broom::glance() %>% 
      pivot_longer(everything(), names_to = "term", values_to = "estimate") %>% 
      mutate(.component = "summary") %>% 
      relocate(.component, 0)
  }
  
  # Get coefs
  coef_ <- tibble()
  if ("coefs" %in% which) {
    coef_ <- tbl %>% 
      pull({{model_col}}) %>% 
      extract2(1) %>% 
      broom::tidy(conf.int = 0.89) %>% 
      mutate(.component = "coefs") %>% 
      relocate(.component, 0)
  }
  
  bind_rows(ms_, coef_)
}
```


### Global model

The global model is very confident of the parameters:

```{r}
lm_all_global <- abt_final %>% 
  summarize(model = list(fit_lm(.))) %>% 
  extract_lm(model, which = "coef")

lm_all_global
lm_all_global[[3,3]] / (1 - lm_all_global[[2,3]])
```

### State model

```{r}
lm_all_state <- unique(abt_final$state_code) %>% 
  future_map_dfr(~ {
    abt_final %>% 
      filter(state_code == .x) %>% 
      group_by(state_code) %>% 
      summarize(model = list(fit_lm(.)), .groups = "keep") %>% 
      group_modify(~ extract_lm(., model, which = "coef"))
  })

lm_all_state %>% 
  group_by(state_code) %>% 
  summarize(beta = estimate[3], gamma = 1 - estimate[2], r0 = beta / gamma)
```

### County model

The county model can be...less confident. And wilder.

```{r}
plan(multiprocess)

lm_all_county <- unique(abt_final$county_fip) %>% 
  future_map_dfr(~ {
    abt_final %>% 
      filter(county_fip == .x) %>% 
      group_by(county_fip) %>% 
      summarize(model = list(fit_lm(.)), .groups = "keep") %>% 
      group_modify(~ extract_lm(., model))
  })

lm_all_county %>% 
  group_by(county_fip) %>% 
  summarize(beta = estimate[3], gamma = 1 - estimate[2], r0 = beta / gamma)
```

There's the expected funnel:

```{r}
abt_final %>% 
  distinct(county_fip, pop) %>% 
  left_join(lm_all_county, .) %>% 
  filter(term == "daily_inf:suscept_norm") %>% 
  ggplot() + 
  geom_point(aes(pop, estimate)) + 
  geom_errorbar(aes(
    estimate, 
    ymin = estimate - 2 * std.error, 
    ymax = estimate + 2 * std.error
  ))
```

And again:

```{r}
abt_final %>% 
  distinct(county_fip, pop) %>% 
  left_join(lm_all_county, .) %>% 
  filter(term == "daily_inf") %>% 
  ggplot() + 
  geom_point(aes(pop, estimate)) + 
  geom_errorbar(aes(
    estimate, 
    ymin = estimate - 2 * std.error, 
    ymax = estimate + 2 * std.error
  ))
```

And plotted against one another. This is...not great.

```{r}
lm_all_county %>% 
  select(county_fip, term, estimate) %>% 
  spread(term, estimate) %>% 
  ggplot() + 
  geom_point(aes(daily_inf, `daily_inf:suscept_norm`)) + 
  ylim(-50, 50) + 
  xlim(-50, 50)
```

### Global model in time

Give it a rolling number of weeks.

```{r}
ROLL_WEEKS <- 6
SHIFT_WEEKS <- 1

output <- tibble()

offset <- 0
while (TRUE) {
  date_min <- min(abt_final$date) + lubridate::weeks(SHIFT_WEEKS) * offset
  date_max <- date_min + lubridate::weeks(ROLL_WEEKS)
  
  coefs <- abt_final %>% 
    filter(date >= date_min, date < date_max) %>% 
    summarize(model = list(fit_lm(.)), .groups = "keep") %>% 
    group_modify(~ extract_lm(., model, which = "coef"))
  
  output <- coefs %>% 
    mutate(min_date = date_min, max_date = date_max) %>% 
    select(min_date, max_date, everything()) %>% 
    bind_rows(output, .)
  
  if (date_max > max(abt_final$date)) break
  offset <- offset + 1
}

output %>% 
  group_by(max_date) %>% 
  summarize(
    beta = estimate[3],
    ub = std.error[3],
    gamma = 1 - estimate[2],
    ug = std.error[2],
    r0 = beta / gamma,
    ur0 = r0 * sqrt((ub/beta)**2 + (ug/gamma)**2),
  ) %>% 
  ggplot(aes(max_date, r0)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = r0-2*ur0, ymax=r0+2*ur0)) + 
  scale_y_continuous(limits = c(-0.5,3), oob=scales::squish)
```

### State model in time

Give it a rolling number of weeks.

```{r}
ROLL_WEEKS <- 6
SHIFT_WEEKS <- 1

output_state <- tibble()

offset <- 0
while (TRUE) {
  date_min <- min(abt_final$date) + lubridate::weeks(SHIFT_WEEKS) * offset
  date_max <- date_min + lubridate::weeks(ROLL_WEEKS)
  
  coefs <- unique(abt_final$state_code) %>% 
    future_map_dfr(~ {
      tmp <- abt_final %>% 
        filter(state_code == .x) %>% 
        filter(date >= date_min, date < date_max)
      
      if (nrow(tmp) == 0) return(tibble())
      
      tmp %>% 
        group_by(state_code) %>% 
        summarize(model = list(fit_lm(.)), .groups = "keep") %>% 
        group_modify(~ extract_lm(., model, which = "coef"))
    })
  
  output_state <- coefs %>% 
    mutate(min_date = date_min, max_date = date_max) %>% 
    select(min_date, max_date, everything()) %>% 
    bind_rows(output_state, .)
  
  if (date_max > max(abt_final$date)) break
  offset <- offset + 1
}

output_state %>% 
  group_by(state_code, max_date) %>% 
  summarize(
    beta = estimate[3],
    ub = std.error[3],
    gamma = 1 - estimate[2],
    ug = std.error[2],
    r0 = beta / gamma,
    ur0 = r0 * sqrt((ub/beta)**2 + (ug/gamma)**2),
  ) %>% 
  ggplot(aes(max_date, r0, color = state_code)) + 
  geom_line() + 
  geom_point() + 
  geom_errorbar(aes(ymin = r0-2*ur0, ymax=r0+2*ur0)) + 
  scale_y_continuous(limits = c(-0.5,3), oob=scales::squish) + 
  facet_wrap(~ state_code) + 
  scale_color_discrete(guide = F)
```


## LME4

```{r}
mm <- lmer(
  daily_inf_p1 ~ daily_inf + daily_inf:suscept_norm + (daily_inf + daily_inf:suscept_norm | state_code), 
  data = abt_final,
  control = lmerControl(optCtrl = list(maxeval = 5e4))
)

summary(mm)
```


### Total

### State level

### County level


## BRMS

### North Carolina example

```{r, include=F, eval=F}
ff <- bf(
  daily_inf_p1 ~ -1 + 
    daily_inf*suscept_norm + 
    (daily_inf*suscept_norm | county_fip)
)

get_prior(ff, abt_final %>% filter(state_code == "NC"))

mm <- brm(
  ff, 
  data = abt_final %>% filter(state_code == "NC"), 
  prior = c(
    prior(normal(0, 1), coef = "daily_inf"),
    prior(normal(0, 1), coef = "daily_inf:suscept_norm")
  ), 
  chains = 4,
  cores = 4
)
```
